# CPU 스케줄링

## 다중처리기 스케줄링
- 여러 CPU를 사용한다면 부하를 공유할수 있지만, 스케줄링은 더욱 복잡해진다.
- CPU들은 큐에 있는 프로세스들을 실행시킬 수 있다. 그러나 동일한 CPU라도 때로는 스케줄링에 제한이 있다.

### 다중처리기 스케줄링 접근 방법
- 첫번째 방법은 주 서버라는 하나의 처리기가 모든 스케줄링 결정과 입출력 처리 그리고 다른 시스템의 활동을 처리하게 하는 것이다. 이것을 `비대칭 다중처리`라 한다.
- 비대칭 다중처리는 단지 한 처리기만 시스템 자료구조에 접근하기 때문에 자료 공유의 필요성을 감소시켜 구현을 간단하게 한다.
- 두번째 방법은 대칭 다중처리(SMP)이다. 각 처리기가 독자적으로 스케줄링한다. 모든 프로세스는 공동 준비완료큐 혹은 각 처리기 마다의 큐를 검사해서 실행할 프로세스를 선택한다. 여러개의 처리기가 공동 자료구조를 접근하고 갱신하려면, 두처리기가 같은 프로세스를 선택하지 않고 프로세스들이 큐에서 사라지지 않는다는 것을 보장해야 한다.

### 처리기 친화성
- 대부분의 SMP 시스템은 한 처리에서 다른 처리기로의 프로세스 이주를 피하고 대신 같은 처리기에서 프로세스를 실행시키려고 한다(`처리기 친화성`). 프로세스의 이주를 위해서는 캐시 메모리의 내용도 이동해야됨으로 오버헤드가 크다.
- OS가 동일한 처리기에서 프로세스를 실행시키려고 노력하는 정책을 가지지만 보장하지는 못할때, `약한 친화성`을 가진다고 한다.
- OS가 시스템 호출을 통하여 프로세스는 다른 처리기로 이주하지 않겠다고 명시하는 것을 `강한 친화성`이라고 한다.

### 로드 벨런싱
- SMP 시스템에서 처리기가 하나 이상이라는 것을 최대한 활용하려면, 부하를 모든 처리기에 균등하게 배분하는 것이 중요하다
- 로드 벨런싱은 SMP 시스템의 모든 처리기 사이에 부하가 균등하게 배분되도록 시도한다. 로드 벨런싱은 통상 각 처리기 마다 자신만의 준비완료 큐를 가지고 있는 시스템에서만 필요한 기능이다.
- 로드벨린성을 위해서는 `push 이주`와 `pull 이주` 방식의 접근법이 있다. 
- push 이주에서는 특정 태스크가 주기적으로 각 처리기의 부하를 검사하고, 만일 불균등 상태로 밝혀지면 과부하인 처리기에서 쉬고 있거나 덜 바쁜 처리기로 프로세스를 이동시킴으로 부하를 분배한다.
- pull 이주는 쉬고 있는 처리기가 바쁜 처리기의 대기 프로세스를 자기 쪽으로 가져오는 것이다.
- push와 pull은 상호 배타적일 필요는 없으며, 종종 병렬적으로 구현된다.

### 다중코어 프로세서
- 각 코어는 구조적인 상태를 유지하기 위한 레지스터 집합을 가지고 있으며, OS 입장에서는 별개의 물리 처리기 처럼 보인다.
- 다중코어 프로세서를 사용하는 SMP 시스템은 여러개의 물리 프로세서를 가지는 시스템에 비해 속도가 빠르고 적은 전력을 소모한다.
- 프로세서가 메모리를 접근할때 데이터가 가용해지기를 기다리면서 많은 시간을 허비하는데 이것을 `메모리 멈춤`이라고 한다. 이러한 상황은 캐시 미스등의 원인으로 발생한다. 이러한 것을 극복하기 위하여 하드웨어 설계에서는 둘 또는 그 이상의 하드웨어 스레드가 각 코어에 할당될 수 있는 다중 스레드 프로세서 코어를 구현한다.
- 다중 스레드 프로세서 코어에서는 한 스레드가 메모리를 기다리면서 멈추면, 코어는 다른 스레드로 전환한다. OS 관점에서 각 하드웨어 스레드는 소프트웨어 스레드를 실행할 수 있는 논리 프로세서로 보인다.
- 일반적으로 처리기를 다중 스레드화하는 데에는 `크게 나눔 다중 스레딩`과 `잘게 나눔 다중 스레딩`의 2가지 방법이 있다.
- 크게 나눔 스레딩은 스레드가 메모리 멈춤과 같은 긴 지연시간을 가진 사건이 발생할 때까지 한 처리기에서 실행된다. 긴 대기시간을 가지게 되면 처리기는 다른 스레드를 실행한다. 그러나 프로세스 코어에서 다른 스레드가 실행되기 전에 명령어 파이프라인이 완전히 정리되어야 하기 때문에 스레드 간 교환 비용이 많이 든다.
- 잘게 나눔 스레딩은 보통 명령어 주기의 경계에서와 같이 좀 더 세밀한 정밀도를 가진 시점에서 스레드 교환이 일어난다. 그러나 잘게 나눔 시스템을 설계하는 경우에는 스레드 교환 회로가 포함된다. 그 결과 스레드 간 교환 비용이 적어진다.
- 다중 스레드 다중 코어 프로세서는 두 단계의 스케줄링이 필요하다. 하나는 어느 프로세스 스레드가 각 하드웨어 스레드(논리 프로세서)에서 실행되어야 하는지를 OS가 결정해야 하는 것, 두번째는 각 코어가 어떤 하드웨어 스레드를 실행시킬 지를 지정하는 것이다.

### 가상화와 스케줄링
- 하나의 CPU를 가졌더라도 가상화를 지원하는 시스템은 다중처리기 시스템처럼 동작할 수 있다.
- 가상화 소프트웨어는 시스템에서 실행 중인 가상기계 마다 하나 이상의 가상 CPU를 제공하고 물리 CPU들을 가상기계가 사용할 수 있도록 스케줄한다.
- 게스트 OS 스케줄링은 비록 각 가상화 OS가 모든 사이클을 받았고 실제고 그 사이클을 모두 스케줄링했다고 믿더라도, 가용한 CPU 사이클의 일부분만 받게 된다. 그렇기 때문에 가상화는 게스트 OS의 완벽한 스케줄링에도 성능이 저하될 수 있다.

## 운영체제 사례들

### Solaris 스케줄링
- 솔라리스는 우선순위 기반 스레드 스케줄링을 사용한다.
- 솔라리스는 우선순위에 따라 시분할, 대화형, 실시간, 시스템, 공평 공유, 고정 우선순위의 스케줄링 클래스를 정의한다. 각 클래스에는 서로 다른 우선순위와 서로 다른 스케줄링 알고리즘이 존재한다.
- 프로세스의 디폴트 스케줄링 클래스는 시분할이다. 시분할 스케줄링은 다단계 피드백 큐를 사용하여 동적으로 우선순위를 바꾸고, 서로 다른 길이의 시간 슬라이스를 할당한다. 디폴트로, 우선순위와 시간 슬라이스 사이에는 반비례 관계가 존재한다. 우선순위가 높을 수록 슬라이스가 작은 식이다. 대화형 프로세스는 높은 우선순위를 가지고 CPU 위주의 프로세스는 낮은 우선순위를 가진다.
- 대화형 클래스는 시분할 클래스와 같은 스케줄링 정책을 사용하지만, 더 나은 성능을 위해 KDE 또는 GNOME 윈도우 관리자에 의해 생성된 윈도우 애플리케이션에 더 높은 우선순위를 준다. 
- 실시간 클래스의 스레드에게는 가장 높은 우선순위가 주어 진다. 이러한 이유는 실시간 프로세스가 제한된 주기 내에 시스템으로 응답을 보장받도록 함이다.
- 솔라리스는 스케줄러와 페이지 디먼과 같은 커널 스레드를 실행하기 위해 시스템 클래스를 사용한다. 일단 설정되면, 시스템 스레드의 우선순위는 바뀌지 않는다. 시스템 클래스는 커널용으로 예약되어 있다.
- 솔라리스9은 고정 우선순위와 공평 공유 스케줄링을 도입하였다.
- 고정 우선순위 클래스에 속한 스레드는 시분할 클래스의 스레드와 같은 우선순위를 가진다. 그러나 이 우선순위는 동적으로 조정되지 않는다.
- 공평 공유 스케줄링 클래스는 스케줄링 결정을 위하여 우선순위 대신에 CPU 공유량을 사용한다. CPU 공유량은 가용한 CPU 자원에 대한 권리를 가리키고 프로젝트라 불리는 프로세스 집합에 할당된다.
- 각 스케줄링 클래스 내에는 우선순위 집합이 있다. 그러나 스케줄러는 클래스 고유의 우선순위를 전역 우선순위로 바꾸며, 가장 높은 전역 우선순위를 가진 스레드를 실행도록 선택한다.
- 같은 우선순위의 스레드가 여러 개 있다면 스케줄러는 RR 큐를 사용한다.
- 솔라리스는 다대다 모델을 사용하였으나 솔라리스9부터는 일대일 모델을 사용한다.

### windows XP 스케줄링
- XP는 우선순위에 기반을 둔 선점 스케줄링 알고리즘을 사용한다.
- XP 커널중 스케줄링을 담당하는 부분을 디스패처라고 부른다.
- 디스패처는 스레드의 실행 순서를 정하기 위하여 32단계의 우선순위를 두고 있다.
- 우선순위는 두 클래스로 구분된다. 가변 클래스에 있는 스레드들은 우선순위가 1~15까지이다. 실시간 클래스는 16~31까지의 스레드를 포함한다. 우선순위가 0인 스레드도 존재하는 데, 이 스레드는 메모리 관리를 위해 사용된다.
- 디스패처는 각 우선순위를 위하여 큐를 사용하고 높은 순위부터 낮은 순위까지 조사하면서 준비 상태의 스레드가 있는지를 본다. 준비 상태에 있는 스레드가 없으면 디스패처는 `idle 스레드`라 불리는 특수 스레드를 실행시킨다.
- 각 스레드의 우선순위는 그 스레드가 속한 우선순위 클래스와 그 클래스 안에서의 상대적인 우선순위에 기반을 둔다.
- 스레드의 시간 할당량이 만료되면 그 스레드는 인터럽트된다. 그 스레드가 가변 우선 순위 클래스에 속하면 우선순위가 낮아진다. 그러나 우선순위가 기본 우선순위보다 낮아지지는 않는다.
- 사용자가 대화형 프로그램을 실행중일때는 시스템은 그 프로세스가 특별히 좋은 성능을 얻도록 해야한다. 그래서 XP는 `NORMAL_PRIORITY_CLASS`에 있는 프로세스들에게 특별한 스케줄링 법칙을 적용한다. XP는 스크린 상 활성중인 (전위)프로세스들과 아닌 (후위)프로세스들을 구분한다. 전위 프로세스가 되면 시간 할당량을 보통 3배 정도 증가시킨다.

### Linux 스케줄링
- 두개의 개별적인 우선순위 범위를 갖는 선점형 우선순위 기반 알고리즘이다.
- 실시간 범위로는 0~99까지의 우선순위를 가지며, nice 범위로는 100~140까지의 우선순위를 가진다. 이 두 범위는 전역 우선순위 구조로 맵핑되고 그안에서 숫자가 더 작은 값이 더 높은 우선순위를 나타낸다.
- 리눅스는 높은 우선순위의 태스크에는 더 긴 시간 슬라이스을 배정하고, 낮은 우선순위의 태스크에는 짧은 시간 슬라이스을 배정한다.
- 실행 가능한 태스크는 시간 슬라이스 중 남은 시간 만큼 CPU 상에서 실행할 자격이 있다고 간주된다. 태스크가 자신의 시간 슬라이스를 소진하면, 만료된 것으로 간주되고 다른 모든 태스크들이 그들의 시간 슬라이스를 소진할 때 까지 실행 가능하지 않게 된다.
- 커널은 모든 실행 가능한 태스크들의 리스트를 runqueue 자료 구조에 유지한다. SMP를 지원하기 때문에 각 처리기는 자신의 runqueue를 각각 관리하고 독립적으로 자신을 스케줄한다.
- 각 runqueue는 active와 expired라는 두 개의 우선순위 배열을 가지고 있다. acitvie 배열은 시간 슬라이스가 남아 있는 모든 태스크들을 포함하고, expired 배열은 모든 만료된 태스크들을 포함한다. 이들 우선순위 배열의 각 원소는 우선순위에 따라 인덱스 된 태스크의 리스트를 가지고 있다.
- 스케줄러는 active 배열에서 가장 우선순위가 높은 태스크를 선택하여 실행한다. 모든 태스크들이 자신의 시간 슬라이스를 소진하여 active 배열이 비게되면, 두 우선순위 배열은 교환된다. expired 배열은 active가 되는 식이다.
- 실시간 태스크는 정적 우선순위를 배정받는다. 모든 다른 태스크들은 nice +/- 5 값을 기반으로 하는 동적 우선순위를 가진다. 태스크의 대화성향이 nice에 5를 더할지 뺄지를 결정한다. 태스크의 대화성향은 입출력을 기다리면서 얼마나 오래 기다렸는지에 의해 결정된다.
- 대화형 태스크는 대기 시간일 길어서 스케줄러에 의해 -5될 가능성이 높고, 대기 시간이 짧은 태스크는 CPU 중심적일 가능성이 커서 우선순위도 낮아진다.
- 태스크의 동적 우선순위는 태스크가 시간 슬라이스를 소진하여 expired 배열로 이동할 때 다시 계산된다.

## 알고리즘의 평가

### 결정론적 모델링
- 평가 방법의 한 중요한 부류로 `분석적 평가`가 있다. 분석적 평가는 주어진 알고리즘과 시스템 작업 부하를 사용하여 공식이나 값을 구한다. 이러한 공식과 값은 작업 부하를 처리하는 알고리즘의 성능을 비교하는데 사용한다.
- 분석적 평가의 한 가지 유형은 `결정론적 모델링`이다.  이 방식은 사전에 정의된 특정한 작업 부하를 받아들여 그 작업 부하에 각 알고리즘의 성능을 정의한다.
- 결정론적 모델링은 단순하고 빠르다. 이 방법은 알고리즘들을 비교할 수 있도록 정확한 값을 제공한다. 그러나 입력으로 정확한 숫자를 요구하며, 그 해답도 단지 주어진 입력의 경우에만 적용된다. 그 해답도 단지 주어진 입력의 경우에만 적용된다.
- 결정론적 모델링은 주로 스케줄링 알고리즘을 설명하고, 본보기를 제공하는 데 사용한다.

### 큐잉 모델
- 프로세스들은 날마다 변화하기 때문에 결정론적 모델링을 사용할 수 있는 프로세스의 정적인 집합이 없다. 그러나 결정할 수 있는 것은 CPU와 입출력 버스트의 분포이다.  이들의 분포는 측정할 수 있으며, 그런 후에 근사 값을 계산하거나 단순하게 추정할 수 있다. 이와 같은 결과로 특정 CPU 버스트의 확률을 기술하는 수학적인 공식을 얻을 수 있다.
- 각 서버는 대기 프로세스들의 큐를 가지고 있다. 도착율과 서비스율을 알면, 이용률, 평균 큐 길이, 평균 대기 시간들을 계산할 수 있다. 이러한 영역에 대한 연구를 큐잉 네트워크 분석이라고 한다.
- 큐잉 분석은 스케줄링 알고리즘을 비교하는 데 그 수와 분포의 부류가 상당히 제한적이다.

### 시뮬레이션
- 시뮬레이터는 변수의 값을 증가시키면서 시스템의 상태를 수정해 장치들, 프로세스 및 스케줄러등의 활동을 반영한다.
- 가장 보편적인 방법은 난수 발생기로, 확률 분포에 따라서 프로세스, CPU 버스트 시간등을 생성하기 위해 프로그램된다.
- 분포에 의해 주도되는 시뮬레이션은 실제 시스템에서 연속적인 사건들 사이에 관계 때문에 부정확할 수 있다.

### 구현
- 스케줄링 알고리즘을 완벽하고 정확하게 평가하는 방법은 실제 코드로 작성해 OS에 넣고 실행해 보는 것이다.
