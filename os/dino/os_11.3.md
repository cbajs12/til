# 파일 시스템 구현

## 복구
- 디스크 상의 디렉터리 구조, 가용 블록 포인터, 가용 FCB 포인터와 같은 파일 시스템 자료구조는 시스템이 크래시될 때 일관성이 깨질 수 있다. 많은 파일 시스템은 이러한 자료구조들에 대한 변경을 바로 그 자리에서 적용하였다. 파일 생성 같은 대표적인 연산은 디스크 상의 파일 시스템 내부의 많은 자료 구조들에 대한 변경을 포함한다. 이러한 변경은 크래시에 의해 방해 받을 수 있고, 이들 구조 사이의 일관성이 깨지는 결과를 초래한다.
- 크래시뿐만 아니라 파일 시스템 구현의 버그, 디스크 컨트롤러 및 사용자 애플리케이션 또한 파일 시스템의 오염을 초래한다. 파일 시스템은 오염을 처리하기 위해서 파일 시스템 자료구조와 알고리즘에 따라 다양한 방법들을 가지고 있다.

### 일관성 검사
- 오염의 원인이 무엇이든 파일 시스템은 문제를 검출하고 교정할 수 있어야 한다. 검출을 위해서 각 파일 시스템의 모든 메타데이터에 대한 검사를 통하여 파일 시스템의 일관성을 확인하거나 부정할 수 있다. 이 검사는 몇 분에서 몇 시간이 소요되며 시스템이 부트될 때 마다 실행되어야 한다. 대체 방안으로 파일 시스템은 파일 메타데이터 안에 자신의 상태를 기록할 수 있다. 메타데이터를 변경하려고 할 때 이 상태 비트는 메타데이터가 변경 중 상태라는 것을 표시하도록 설정되어야 한다. 메타데이터에 대한 모든 갱신이 성공적으로 완료되면, 파일 시스템은 이 비트를 소거한다. 그러나 상태 비트가 1로 남아 있으면, 일관성 검사가 실행된다.
- 일관성 검사기는 디렉터리 구조에 있는 데이터와 디스크에 있는 데이터 블록을 비교하고 불일치가 발견되면 그것을 정정하려고 한다. 이 일관성 검사기에는 UNIX의 fsck와 Windows의 chkdsk등이 있다. 이때 할당 및 가용 공간 관리 알고리즘이 이 검사기가 발견할 수 있는 문제의 유형과 이들을 얼마나 성공적으로 회복할 수 있을 지를 결정한다. 예를 들면, 연결 할당이 사용되고 모든 블록이 다음 블록에 대한 링크를 가지고 있다면 데이터 블록으로부터 전체 파일을 재구축할 수 있다, 아울러 디렉터리 구조도 다시 만들수 있다. 이와는 대조적으로 색인 할당 시스템에서 디렉터리 항목을 잃으면 상황은 심각하다. 파일의 데이터 블록들은 서로에 대한 정보를 하나도 가지고 있지 않기 때문이다. 이러한 이유로 UNIX는 읽기를 위한 디렉터리 항목들만 캐시하고 공간 할당이나 다른 메타데이터 변경을 유발하는 데이터 쓰기는 해당 데이터 블록이 써기지 전에 동기식으로 실행한다. 물론, 동기식 쓰기를 실행할 경우에도 시스템 크래시가 중간에 발생하는 경우 부분적인 정보를 잃는 문제는 여전히 존재한다.

### 로그 구조 파일 시스템
- 로깅 알고리즘은 일관성 검사의 문제에 성공적으로 적용되었다. 그 결과물은 `로그 기반 트랜잭션 저널링` 파일 시스템으로 알려져 있다.
- 이전의 일관성 검사 기법을 쓴다면 깨진 일관성을 복구하지 못할 수도 있다. 이 문제의 해결 방안은 파일 시스템 메타데이터 갱신에 로그 기반 복구 기술을 적용하는 것이다. NTFS와 Veritas 파일 시스템 모두 이 기술을 사용하며, Solaris 7 이상 버전의 UFS에서는 이 기술을 옵션으로 제공한다. 
- 기본적으로 모든 메타데이터 변경은 로그에 순차적으로 기록도니다. 특정 태스크를 실행하는 연산의 집합 각각을 하나의 트랜잭션이라고 한다. 일단 변경이 이 로그에 기록되면 그들을 commit된 것으로 간주되고, 시스템 호출은 사용자 프로세스로 복귀하여 실행을 계속한다. 그동안 이 로그 엔트리는 실제 파일 시스템 구조를 넘나들며 재실행 된다. 변경이 반영될 때마다 어느 동작이 끝났는지, 그리고 어느 것이 아직 덜 끝났는지를 나타내기 위해 포인터가 갱신된다. 커밋된 트랜잭션 전부가 완료되면 로그 파일로부터 제거된다. 
- 로그 파일은 실제로 윈형 버퍼이다. 원형 버퍼가 버퍼 공간의 맨 뒤에 기록된 후에는 맨 앞에서 다시 시작하기 때문에 이전의 데이터 위에 겹쳐 쓰게 된다. 아직 저장되지 않은 데이터 위에 새로운 데이터가 덮여 쓰이기를 윈하지 않기 때문에 그런 상황이 발생하지 않도록 해야 한다. 로그는 파일 시스템의 별도 섹션에 있을 수도 있고 별도의 디스크에 있을 수도 있다. 로그를 개별 읽기/쓰기 헤드 아래에 두어 헤드 경쟁과 탐색시간을 줄이는 것은 효율적이지만 복잡하다.
- 시스템이 크래시되면, 로그 파일에 0개 이상의 트랜잭션이 잇을 것이다. 이런 트랜잭션들은 OS에 의해 커밋되었을지라도 파일 시스템에서 결코 실행이 완료되지 않은 것이기 때문에 이들은 반드시 실행을 완료해야 한다. 이 트랜잭션들은 포인터로부터 작업이 완료될 때까지 실행될 수 있고, 파일 시스템 구조는 일관성을 유지하게 된다. 유일한 문제는 트랜잭션이 중단되었을 때 발생한다. 즉 그 트랜잭션은 시스템이 크래시하기 전에 커밋되지 않은 것이다. 이러한 트랜잭션에 의해 변경된 파일 시스템의 내용은 원상 복구해야 파일 시스템의 일관성을 유지할 수 있다. 이러한 복구는 크래시가 발생한 후 필요한 유일한 일로 일관성 검사 시의 모든 문제를 해결한다.
- 디스크 메타데이터를 갱신할 때 로그를 사용하는 부수적 이득은 이들을 디스크 데이터 구조에 직접 적용하는 것보다 갱신이 더 빠르다는 것이다. 이러한 성능 향상의 이유는 임의 입출력에 비해 순차 입출력이 빠르다는 데서 찾을 수 있다. 비용이 많이 드는 동기식 임의 메타데이터 쓰기가 로그 구조 파일 시스템의 로깅 지역에 행해지는 비용이 적은 동기식 순차 쓰기로 변환된다. 다시 이러한 변경은 해당 구조에 대한 임의 쓰기를 통하여 비동기적으로 재실행된다.

### 다른 해결 방안들
- 다른 해결방안의 시스템들은 옛 데이터를 새 데이터로 절대로 덮어쓰지 않는다. 오히려 트랜잭션은 모든 데이터와 메타데이터 변경을 새로운 블록에 기록한다. 트랜잭션이 완료되면 이 블록들의 구 버전을 가리키고 있는 메타데이터 구조가 새로운 블록들을 가리키도록 갱신된다. 그런 후에 파일 시스템은 구 포인터들과 옛 블록들을 제거하여 재사용 가능하게 만든다. 만일 옛 포인터와 블록들을 유지한다면 스냅샷을 생성하는 것이 된다. 이 스냅샷은 마지막 갱신이 일어나기 전에 파일 시스템의 상태가 된다. 이 해결 방안은 포인터 갱신이 자동적으로 일어난다면 일관성 검사가 필요없게 된다. 그러나 몇몇 고장 시나리오는 메타데이터 오염을 초래할 수 있다.
- Sun의 ZFS는 메타데이터와 데이터 블록의 검사-홍합을 제공한다. 이 해결책은 RAID와 결합될 때 데이터가 항상 올바르다는 것을 보장한다.

### 백업과 복구
- 디스크는 고장을 일으키고, 그러한 고장 중에 손실된 데이터가 영구 손실이 없도록 해야한다. 이 때문에 디스크 내용을 백업하기 위한 시스템 프로그램이 사용될 수 있다. 이렇게 되면 개별적인 파일 또는 전체 디스크의 손실은 백업 데이터로부터 복구만 하면 된다.
- 복사의 양을 최소화하기 위해 각 파일의 디렉터리 항목 정보를 이용할 수 있다. 예를 들면, 백업 프로그램이 파일이 마지막으로 백업된 시간과 마지막 백업 후 파일이 변경되지 않았다는 것을 알면, 그 파일을 다시 복사할 필요가 없다.
- 전체 백업부터 시작하여 모든 점증적 백업을 하나씩 순서대로 적용함으로써 전체 디스크를 복원할 수 있다.

## NFS
- NFS는 클라이언트 시스템의 전체적인 디렉터리 구조 및 인터페이스와 통합되어 있다. NFS는 널리쓰이는 잘 구현된 클라이언트 서버 네트워크 파일 시스템의 좋은 예이다.
- NFS는 LAN을 거쳐 원격 파일을 접근하기 위한 소프트웨어 시스템의 구현과 명세 모두를 말한다. NFS는 상호 연결 네트워크에 따라 TCP 또는 UDP/IP 두 가지 중 하나를 사용한다.

### 개요
- NFS는 서로 연결된 워크스테이션의 집합을 독립적인 파일 시스템을 가진 독립적인 기계들의 집합으로 간주한다. NFS의 목적은 이들 파일 시스템들 사이에서 일정 수준의 공유를 투명하게 허용하는 것이다. 공유는 클라이언트 서버의 관계를 기반으로 한다. 한 시스템은 종종 동시에 클라이언트와 서버가 될 수 있다. 공유는 전용의 서버 시스템들 사이보다는 임의의 한 쌍의 기계 사이에서 허용된다. 시스템의 독립성을 보장하기 위해서 원격 파일 시스템의 공유는 다른 시스템에는 영향을 미치지 않고 단지 클라이언트에게만 영향을 준다.
- 원격 디렉터리가 특정 시스템(m1)으로부터 투명하게 접근 가능하도록 하기 위해서 m1의 클라이언트는 먼저 마운트 연산을 실행한다. 이 연산은 원격 디렉터리가 로컬 파일 시스템의 서브트리처럼 보이며, 로컬 디렉터리의 기존 서브트리를 대체한다. 로컬 디렉터리는 새로 마운트된 디렉터리 루트의 이름이 된다. 마운트 연산을 위해 전달되는 매개변수로 원격 디렉터리를 지정하는 일은 투명하지 않은 방식으로 실행된다. 즉, 원격 디렉터리의 위치가 반드시 제공되어야 한다. 그러나 일단 마운트되고 나면, 시스템 m1의 사용자들은 원격 디렉터리에 존재하는 파일에 로컬 디렉터리에 존재하는 파일처럼 접근할 수 있다.
- 접근 권한만 허용한다면 기본적으로 어느 파일 시스템 또는 파일 시스템 내의 어느 디렉터리든 임의의 로컬 디렉터리에 원격으로 마운트될 수 있다. 디스크가 없는 워크스테이션은 심지어 서버들로부터 그들 자신의 루트를 마운트할 수 있다.
- 일부 NFS에서는 연속 마운트 또한 허용된다. 즉, 한 파일 시스템이 이미 원격 마운트된 파일 시스템에 다시 마운트될 수 있다. 기계는 단지 자신이 호출한 마운트에 의해서만 영향을 받는다. 원격 파일 시스템을 마운트해도 클라이언트는 원격 파일 시스템에 우연히 이미 마운트되어 있던 다른 파일 시스템에는 접근할 수 없다. 그러므로 마운트 기법은 이행성 특성을 갖지 않는다.
- NFS의 설계 목표 중의 하나는 서로 다른 기계들, OS, 그리고 네트워크 구조로 구성된 이질적 환경에서 작동하는 것이다. NFS 명세는 이들 매체에 독립적이라서 구현 방법을 다르게 하는 것을 권장한다. 이러한 독립성은 두 개의 구현 독립적 인터페이스간에서 사용되는 외부 자료 표현(XDR) 프로토콜 위에 구축된 RPC 프리미티브를 통해서 이루어진다. 따라서 NFS와 정확하게 인터페이스되는 이기종 시스템과 파일 시스템으로 구성된 시스템에서는 다른 타입의 파일 시스템들도 로컬 또는 원격으로 마운트될 수 있다.
- NFS 명세는 마운트 기법에 의해 제공되는 서비스와 실제 원격 파일 접근 서비스를 구분한다. 따라서 이들 서비스들을 위해 두 가지의 다른 프로토콜이 명세되어 있다. 즉, 마운트 프로토콜과 NFS 프로토콜이라 불리는 원격 파일 접근을 위한 프로토콜들이 그것이다. 이들 프로토콜은 RPC 집합형태로 명세되어 있다. 이들 RPC는 투명한 원격 파일 접근을 구현하기 위해 사용되는 빌딩 블록이다.

### 마운트 프로토콜
- 마운트 프로토콜은 서비스와 클라이언트 사이에 최초의 논리적 연결을 생성하기 위해서 사용된다.
- 마운트 연산은 마운트될 원격 디렉터리의 이름과 그것을 저장하고 있는 서버 기계의 이름을 포함한다. 마운트 요청은 적절한 RPC로 맵핑되고, 지명된 서버 기계 상에서 실행되는 마운트 서버로 전달된다. 서버는 export list를 유지하며, 이 목록은 마운트할 수 있도록 export하는 로컬 파일 시스템을 지정하고, 더불어 그것들을 마운트하도록 하가받은 기계의 이름을 함께 명시한다. export list와 마운트 테이블의 유지 관리를 간단하게 하기 위해 분산 지명 기법을 사용하여 이러한 정보를 저장하고, 적합한 클라이언트에게 이를 제공할 수 있다.
- export된 파일 시스템 내의 임의의 디렉터리는 인가받은 기계에 의해서 원격으로 마운트될 수 있다. 그러므로 구성단위는 이들 디렉터리가 된다. 서버가 자신의 export list가 허용하는 마운트 요청을 받았을 때, 서버는 클라이언트에게 향후 마운트된 파일 시스템 안의 파일에 접근할 때 키로 사용할 파일 핸들을 반환한다. 이 파일 핸들은 서버가 저장하고 있는 개별 파일을 구분하기 위해서 필요한 모든 정보를 가지고 있다. UNIX에서, 파일 핸들은 파일 시스템 식별자와 export된 파일 시스템 내의 마운트된 디렉터리를 정확히 가리키는 inode번호로 구성된다.
- 서버는 또한 클라이언트 시스템의 리스트와 각 시스템에 현재 마운트된 디렉터리를 유지한다. 이 리스트는 주로 관리 목적을 위해서 사용되는데, 예를 들면, 서버에 고장이 발생했다는 것을 모든 클라이언트들에게 알려주는 것 등이다. 이 리스트에 한 항목을 추가하고 삭제하는 일이 마운트 프로토콜에 의해 서버의 상태가 영향 받을 수 있는 유일한 방법이다.
- 일반적으로 시스템은 부트 시에 구축되는 정적 마운트 사전 구성을 갖지만, 이 배치는 변경될 수 있다. 실제 마운트 프로시저외에 마운트 프로토콜은 언마운트와 export list 반환과 같은 여러 프로시저를 가지고 있다.

### NFS 프로토콜
- NFS 프로토콜은 원격 파일 연산을 위한 원격 프로시저 호출의 집합을 제공한다. 디렉터리 내 파일 검색, 디렉터리 항목 집합 읽기, 링크와 디렉터리들의 조작, 파일 속성의 접근, 파일 읽기와 쓰기등이다. 이러한 프로시저는 원격으로 마운트된 디렉터리에 대한 파일 핸들이 구축되어야만 호출할 수 있다.
- NFS 서비스의 주요 특징은 무상태성이다. 서버는 하나의 접근과 다른 접근 사이에 클라이언트에 대한 정보를 유지하지 않는다. 서버에 UNIX의 열린 파일 테이블 또는 파일 구조와 비슷한 구조가 존재하지 않는다. 결론적으로 각각의 요구들은 적절한 동작을 위해서는 유일한 파일 식별자와 파일 내부의 절대적인 오프셋과 같은 모든 인자들을 제공해야 한다. 이러한 설계 방식은 견고성을 증진시킬 수 있다. 왜냐하면 시스템 크래시 후 서버를 복원하기 위해 특별한 대책이 필요 없기 때문이다. 파일 연산은 이 목적을 위하여 먹등이 될 필요가 있다. 모든 NFS 요청은 일련번호를 가지고 있어서 서버는 한 요청이 중복되었는지 또는 빠졌는지를 알 수 있다.
- 마운트 프로토콜에서 설명된 클라이언트의 리스트를 유지하는 것은 서버의 무상태 원칙을 위반한 것처럼 보인다. 그러나 이 리스트는 클라이언트나 서버의 정확한 동작을 위해 필수적이 아니며, 따라서 이 리스트는 서버 크래시 후 복구될 필요가 없다. 결과적으로 이 리스트는 일관성이 없는 자료를 포함할 수 있으며, 단지 힌트로서만 취급된다.
- 서버의 무상태 철학과 RPC의 동기성이 갖는 부가적인 의미는 결과가 클라이언트에 반환되기 전에 변경된 자료가 서버의 디스크에 기록되어야 한다는 것이다. 즉, 클라이언트가 쓰기 블록들을 캐시할 수 있지만, 클라이언트가 쓰기 블록들을 서버로 플러시할 때는 그것들이 서버의 디스크에 반영된 것으로 가정한다. 서버는 모든 NFS 데이터를 동기적으로 써야만 한다. 그러므로 서버의 크래시와 복구는 클라이언트에게는 보이지 않는다. 즉, 클라이언트를 위해 서버가 관리하고 있는 모든 블록들은 안전하나 결과적으로 성능에 있어서는 큰 문제가 발생한다. 캐싱의 장점을 얻지 못하기 때문이다. 성능은 자신만의 비휘발성인 캐시를 사용하면 향상될 수 있는데, 이 캐시는 예비 배터리를 가지고 있다. 디스크 제어기는 데이터가 비휘발성 캐시에 저장되면 디스크 쓰기가 완료되었음을 알린다. 따라서 호스트는 대단히 빠른 동기식 쓰기를 할 수 있다. 이런 블록들은 시스템 크래시 후에도 안전하게 남아 있으며, 이 안정된 저장장치로부터 디스크로 주기적으로 기록된다.
- 하나의 NFS 쓰기 프로시저 호출은 원자성이 보장되며, 같은 파일에 대한 다른 쓰기 호출과 혼합되지 않는다. 그러나 NFS 프로토콜은 병행성 제어 기법을 제공하지 않는다. 쓰기 시스템 호출은 여러 개의 RPC 쓰기로 분리될 수 있는데, 그 이유는 각 NFS 쓰기 또는 읽기 호출은 최대 8KB의 자료를 포함할 수 있고, UDP 패킷은 1500바이트로 제한되어 있기 때문이다. 결과적으로 같은 원격 파일에 대해 쓰기를 하는 두 사용자는 그들의 데이터가 뒤섞일 수도 있다. 이러한 문제는 록 관리가 본질적으로 상태성이므로, NFS 외부의 서비스가 록을 제공해야만 해결될 수 있다고 한다. 사용자들은 NFS를 벗어난 별도의 기법을 사용해서 공유 파일에 대해 서로 협력하면서 접근해야만 한다.
- NFS는 가상 파일 시스템(VFS)을 통하여 OS로 통합된다. 클라이언트는 정규 시스템 호출을 통해서 연산을 시작한다. OS 층은 이 호출을 적절한 vnode에 대한 VFS 연산으로 맵핑한다. VFS 계층은 이 파일을 원격 파일로 인식하고 적절한 NFS 프로시저를 실행한다. 원격 서버 내의 NFS 서비스 계층을 목적지로 RPC 호출을 한다. 이 호출은 원격 시스템 상의 VFS 계층으로 다시 들어가고, 원격 시스템은 그 호출의 로컬함을 발견하며, 적절한 파일 시스템 연산을 실행한다. 결과를 반환하기 위하여 이 경로를 되밟아 간다. 이러한 구조의 장점은 클라이언트와 서버가 동등하므로, 시스템이 클라이언트나 서버 모두가 될 수 있다는 것이다.

### 경로 이름 변환
- NFS에서의 경로 이름 변환은 파일의 경로 이름을 파싱하는 것을 포함한다. 경로 이름 변환은 경로를 구성요소 이름으로 분리하고, 구성요소 이름과 디렉터리 vnode의 모든 쌍에 대한 각각의 NFS lookup 호출을 실행함으로써 이루어 진다. 일단 마운트 포인트를 넘어가면, 모든 구성요소 룩업은 서버에 대해 개별적인 RPC를 유발한다. 이렇게 많은 비용이 소요되는 경로 이름 순회 기법이 필요한 이유는 각 클라이언트가 실행한 마운트에 의해 생겨난 자신의 논리적 이름 공간의 배치가 특유하기 때문이다. 일단 마운트 포인트를 만나면, 서버에게 경로 이름을 주고, 목적 vnode를 받는 것이 더욱 효율적일 수도 있다. 그러나 임의의 시점에 같은 클라이언트가 마운트한 또 다른 마운트 포인트가 있을 수 있고, 무상태성 서버는 이에 대해서 알지 못하기 때문에 사용할 수 없다.
- 검색을 더 빠르게 하기 위해서 클라이언트 측의 디렉터리 이름 룩업 캐시는 원격 디렉터리 이름들에 대한 vnode를 가지고 있다. 이 캐시는 시작 부분이 같은 경로 이름을 가진 파일들에 대한 참조 속도를 증가시킨다. 서버로부터 반환된 속성과 캐시된 vnode의 속성이 일치되지 않을때 디렉러티 캐시는 폐기된다.
- 일부 NFS에서는 연속 마운트를 허용하지만 서버가 클라이언트와 또 다른 서버 사이에서 중재자로서 행동할 수는 없다. 대신 클라이언트는 원하는 디렉터리를 직접 마운트함으로써, 두 번째 서버와 직접 클라이언트 서버 연결을 생성해야 한다. 클라이언트가 연속 마운트를 가질 때 경로 이름 순회 시에 하나 이상의 서버가 관련될 수 있다. 그러나 각 구성요소 룩업은 원래의 클라이언트와 해당 서버 사이에서 실행된다. 그러므로 서버가 파일 시스템을 마운트한 디렉터리 상에서 클라이언트가 룩업을 실행할 때 클라이언트는 마운트된 디렉터리가 아닌 원래의 디렉터리를 보게 된다.

### 원격 연산
- 파일의 열기와 닫기를 제외하면 파일 연산을 위한 정규 UNIX 시스템 호출들과 NFS의 RPC 프로토콜들 간에는 거의 1:1 대응 관계가 있다. 그러므로 원격 파일 연산은 대응되는 RPC로 직접 변환될 수 있다. 개념적으로 NFS는 원격 서비스 패러다임을 따르지만, 실제로는 성능 향상을 위해 버퍼링과 캐싱 기술을 사용한다. 하나의 원격 연산과 하나의 RPC 사이에 직접적인 대응 관계는 존재하지 않는다. 대신 파일 블록들과 파일 속성들이 RPC들에 의해서 반입되며 로컬하게 캐시된다. 그 뒤의 원격 명령들은 일관성 제약이 허락하는 한 캐시 자료를 사용한다.
- 파일 속성 캐시와 파일-블록 캐시 2개의 캐시가 존재한다. 파일을 열때, 커널은 캐시된 속성들을 다시 가져올지 또는 이전 것을 다시 사용할지를 결정하기 위해 원격 서버를 검사한다. 캐시된 파일 블록들은 대응되는 캐시된 속성들이 최신 버전일 경우에만 사용한다. 서버로부터 새로운 속성들이 도착될 때마다 캐시된 속성이 갱신된다. 캐시된 속성들은 디폴트로 60초 후에 버린다. 미리 읽기 기법과 지연 쓰기 기법들 모두가 서버와 클라이언트 간에서 사용된다. 클라이언트는 서버가 자료를 디스크에 기록한 것을 확인하기 전까지는 지연 쓰기 블록을 방출하지 않는다. 지연 쓰기는 파일이 서로 충돌 모드로 동시에 열릴 때에도 유지된다. 그러므로 UNIX의 semantics는 유지되지 않는다.
- 성능을 위한 시스템의 조정은 NFS의 일관성 semantics를 특정 짓기 어렵게 만든다. 그 파일에 대한 새로운 열기는 서버의 디스크에 이미 반영된 내용만 볼 수 있다. 그러므로 NFS는 UNIX semantics를 엄격히 따르지 않을 뿐만 아니라 Andrew의 세션 의미도 제공하지 않는다.

## 예: WAFL 파일 시스템
- 디스크 입출력은 시스템의 전반적인 성능에 상당한 영향을 미친다, 그 결과, 파일 시스템의 설계 및 구현은 파일 시스템의 설게자 입장에서 매우 주의를 요하는 작업이다. WAFL 파일 시스템은 특정한 시스템을 위하여 최적화된 파일 시스템의 하나이다. 무작위 쓰기 연산에 대하여 최적화된 성능이 뛰어난 파일 시스템이다.
- WAFL은 NFS와 CIFS만을 위하여 설계되었으나, NFS, CIFS, FTP 및 HTTP 프로토콜을 통하여 클라이언트에게 파일을 제공한다. 다수의 클라이언트들이 파일 서버와 통신하기 위하여 이러한 프로토콜을 사용할 경우, 서버는 매우 대략의 무작위 읽기 요청 및 그보다 더 대용량의 무작위 쓰기 요청을 받게 될 것이다. 이러한 상황에서 NFS와 CIFS 프로토콜은 읽기 연산으로부터 데이터를 캐시하고, 따라서 파일 서버 개발자에게는 쓰기 연산이 큰 걱정거리이다.
- WAFL은 쓰기 연산을 위한 NVRAM 캐시를 갖는 파일 서버에서 사용된다. WAFL의 설계자는 무작위 입출력을 최적화하기 위해 특정 아키텍처에서 실행된다는 점과 안정 저장장치 캐시의 이점을 활용하였다. WAFL은 전용 장치들에서 사용되도록 설계되었기 때문에 사용의 용이성이 설계지침 중 하나이다. 또한, WAFL 개발자들은 새로운 스냅샷 기능을 제공한다. 이 스냅샷 기능은 여러 다른 시점에서 파일 시스템의 읽기 전용 복사본을 만든다.
- 이 파일 시스템은 FFS와 유사하지만 많이 수정되었다. 이는 블록 기반이고 파일을 기술하기 위하여 inode를 사용한다. 각 inode는 16개의 포인터를 갖고, 각 포인터는 파일이 사용하고 있는 블록을 가리키기 위하여 사용도니다. 각 파일 시스템은 루트 inode를 갖고, 모든 메타데이터는 파일에 존재한다. 모든 inode는 하나의 파일에 존재하고, 가용 블록 맵도 역시 또 다른 파일에 존재한다. 이들은 모두 일반 파일이기 때문에 데이터 블록은 위치에 구애받지 않고 어디에든 존재할 수 있다. 디스크가 추가되어 파일 시스템이 확장될 경우, 이러한 메타데이터 파일의 크기는 파일 시스템에 의하여 자동적으로 확장된다.
- 따라서 WAFL 파일 시스템은 루트 inode를 기점으로 하는 블록들의 트리로 구성된다. 스냅샷을 작성하기 위하여 WAFL은 루트 inode의 복사본을 생성한다. 모든 파일 및 메타데이터의 갱신은 기존 블록을 덮어 쓰는 것이 아니라 새로운 블록에서 행해진다. 새 루트 inode는 이러한 쓰기 연산의 결과로 변경된 메타데이터와 데이터를 가리킨다. 반면에, 스냅샷은 업데이트되지 않았으므로, 여전히 기존의 데이터 블록들을 가리키고 있을 것이다. 그러므로 기존 루트 inode는 스냅샷 생성 당시의 파일 시스템에 접근할 수 있게 한다. 그것도 매우 작은 공간을 소모하면서 제공한다. 중요한 사실은 스냅샷이 차지하는 디스크 공간은 스냅샷 이후에 변경된 블록 정도가 된다.
- 대부분의 일반 파일 시스템과 다른 중요한 변화는 가용 블록 맵이 블록 당 1비트 이상을 사용한다는 것이다. 블록을 사용하고 있는 각 스냅샷을 나타내기 위한 비트 집합 형태의 비트맵이다. 블록을 사용 중이던 모든 스냅샷이 삭제되면, 해당 블록에 대한 비트맵은 모두 0으로 설정될 것이고, 해당 블록은 재사용되도록 반환한다. 사용했던 블록들은 절대 덮어 쓰이지 않으므로, 현재의 헤드 위치에서 가까운 가용 블록에 쓰기 작업을 할 수 있기 때문에 쓰기 작업이 매우 빠르게 행해진다. 그 외에도 다양한 성능 최적화 기법들이 WAFL에서 사용된다.
- 다수의 스냅샷이 동시에 존재할 수 있고, 따라서 스냅샷이 매 시간마다 그리고 매일 작성될 수 있다. 스냅샷 기능은 백업을 위해서도 상당히 유용하고, 테스트와 버전 관리를 위해서도 활용될 수 있다. WAFL의 스냅샷 기능은 브롥이 변경되기 전에 각 데이터 블록에 대한 쓰기-시-복사조차 필요로 하지 않는다. 다른 파일 시스템들도 스냅샷 기능을 제공하지만, 보다 효율적으로 동작한다.
- WAFL의 새 버전들은 실제적으로 클론이라고 알려진 읽기-쓰기 스냅샷을 허용한다. 또한, 이 클론은 스냅샷과 동일한 기법을 사용하기 때문에 효율적이다. 이 경우 읽기 전용 스냡샷은 파일 시스템의 상태를 포착하고 클론은 이 읽기 전용 스냅샷을 역으로 가리킨다. 클론에 행해지는 쓰기는 새로운 블록에 저장되고 클론의 포인터는 갱신되어 새로운 블록을 가리키게 된다. 원본 스냅샷은 변경되지 않기 때문에 클론이 갱신되기 이전에 유지하던 파일 시스템 상태를 제공한다. 클론은 또한 원본 파일 시스템을 대체하도록 상승될 수 있다. 이 상승은 모든 기존 포인터와 연관된 기존 블록들을 폐기한다. 클론은 원본이 변경되지 않은 상태에서 테스팅이 끝나거나 업그레이드가 실패할 경우 클론만 삭제하면 되기 때문에 테스팅과 업그레이드에 유용하다.
- WAFL 파일 시스템 구현으로부터 도출되는 다른 특징은 복제로서 네트워크를 통한 다른 시스템으로의 데이터의 중복과 동기화 기능이다. 우선 WAFL의 스냅샷이 다른 시스템으로 중복된다. 소스 시스템에서 다른 스냅샷이 취해지면 새로운 스냅샷에 포함된 모든 블록을 전송하면 되기 때문에 원격 시스템을 갱신하는 것이 상대적으로 쉽다. 이 블록들을 파일 시스템에 추가하고 자신의 포인터를 갱신하면 두 번째 스냅샷이 취해진 시점의 소스 시스템과 동일한 새로운 시스템을 구축할 수 있다. 이러한 과정을 반복하면 원격 시스템을 첫 번째 시스템과 거의 같은 복사본 형태로 유지할 수 있다. 이러한 중복은 재앙 복구에 사용된다. 첫 번째 시스템이 폐기되어야 한다면 거의 대부분의 데이터를 원격 시스템에서 찾을 수 있다.
