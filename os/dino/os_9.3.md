# 가상 메모리

## 메모리 사상 파일
- 가상 메모리 기법을 사용하여 파일 입출력을 일반적인 메모리 참조 방식으로 처리할 수 있다. 이것을 `파일의 메모리 매핑`이라 한다. 이 방법은 가상 주소 공간의 일부가 논리적으로 파일과 관련되게 한다. 이 방식은 입출력을 실행할 때 현저한 성능 향상을 제공한다.

### 기본 메커니즘
- 파일의 메모리 매핑은 하나의 디스크 블록을 메모리의 한 페이지 또는 페이지들로 매핑함으로써 이루어진다. 첫 번째 접근은 일반적인 요구 페이징 과정에 따라 페이지 부재를 발생시킨다. 그러나 그 파일 중 페이지 크기만큼의 해당 부분이 파일 시스템으로부터 물리 페이지로 읽혀 들어오게 된다. 그 이후의 파일 읽기/쓰기는 다른 메모리 엑세스처럼 처리된다. 이 방법은 read()와 write() 시스템 호출을 사용하는 오버헤드를 유발시키지 않고 메모리를 통해 파일을 조작할 수 있기 때문에 파일 접근과 사용을 간단하게 한다. 유사하게 파일 입출력이 메모리에 실행되면 디스크 입출력을 발생시키는 시스템을 사용할 때와 반대로 파일에 훨씬 빠르게 접근할 수 있다.
- 메모리에 매핑된 파일에 대한 쓰기는 디스크에 동기적으로 반영되지 않을 수도 있다. 시스템에 따라서는 OS가 주기적으로 메모리 페이지의 변경여부를 검사할 때, 물리 파일에 반영하기도 한다. 프로세스가 파일을 닫으면 모든 메모리 매핑 데이터는 디스크에 쓰이고 가상 메모리에서 제거된다.
- 어떤 OS는 특정 시스템 호출을 메모리 매핑을 지원하고, 모든 다른 파일 입출력을 실행하기 위해서는 표준 시스템 호출을 사용한다. 반면 어떤 OS는 지정된 파일이 메모리 매핑 파일인지 관계없이 메모리 매핑을 허용한다.
- 여러 프로세스들은 같은 파일을 동시에 메모리 매팽할 수 있으며, 이는 데이터를 공유하는 효과를 낳는다. 이러한 경우 한 프로세스가 공유 중인 메모리 매핑 파일을 수정하면 같은 영역을 매핑하는 다른 모든 프로세스들도 볼 수 있게 된다. 
- 메모리 매핑 영역 구현은 그 파일을 공유하는 프로세스들의 가상 메모리 맵은 모두 디스크 블록의 복사본을 적재하고 있는 물리 메모리의 같은 페이지를 가리도록 구현한다. 또한, 메모리 매핑 시스템 호출들은 쓰기시-복사 기능을 지원하여 파일을 읽기 모드로 모든 프로세스들이 한 개의 페이지를 공유하다가, 어떤 프로세스가 그것을 수정하기 시작하면 그 시점에 그 프로세스를 위해 별도의 페이지 복사본을 만들어 준다. 공유 데이터에 대한 접근을 조율하기 위하여 참여 프로세스들은 상호 배제를 보장해야한다.
- 다양한 측면에서 메모리 매핑 파일의 공유는 공유 메모리와 비슷하다. 모든 시스템이 양쪽에 대해 같은 메커니즘을 사용하는 것은 아니다. UNIX/LINUX 시스템에서는 메모리 매핑이 mmap() 시스템 호출을 통해 이루어지는 반면, 공유 메모리는 POSIX 호환의 shmget(), shmat() 시스템 호출에 의해 처리된다. Windows XP 시스템에서는 공유 메모리를 메모리 매핑 파일을 이용하여 구현한다. 이들 시스템에서는 프로세스들이 같은 파일을 자신의 가상 주소 공간으로 메모리 매핑함으로써 서로 통신할 수 있다. 통신하는 프로세스들 간에서 메모리 매핑된 파일이 공유 메모리 영역의 역할을 한다.

### Win32 API에서 공유 메모리
- 이 API에서 메모리 매핑 파일을 이용하여 공유 메모리를 생성하는 전체적인 과정은 먼저 매핑될 파일에 대한 파일 매핑을 생성하고, 매핑된 파일의 프로세스가 가상 주소 공간상의 뷰를 만든다. 다른 프로세스는 파일을 연 뒤 매핑된 파일의 뷰를 가상 주소 공간상에 생성한다. 매핑된 파일은 프로세스들 간의 통신을 위한 공유 메모리 객체를 나타낸다.
- 매핑을 만드는 과정에서 모든 매핑이 메모리로 적재되지 않을 수도 있다. 매핑된 파일은 요구 페이징을 통해 실제로 접근될 때 필요한 페이지들이 적재된다.

### 메모리 사상 I/O
- 각 I/O 컨트롤러는 명령어와 전송할 데이터를 담기 위한 레지스터들을 포함하고 있다. 이러한 레지스터와 시스템 메모리 같의 데이터 전송을 위해서는 대개 특별한 I/O 명령어가 사용된다.
- 많은 컴퓨터 구조는 메모리 매핑 I/O 기능을 제공하고 있다. 특정 메모리 영역이 장치 레지스터들을 매핑할 수 있도록 유보해 둔다. 이러한 주소에 대한 읽기, 쓰기 작업은 장치 레지스터로의 데이터 전송으로 처리된다.
- 메모리 매핑 I/O는 모뎀이나 프린터를 연결하는 직렬/병렬 포트에도 편리하다. CPU는 이러한 종류의 장치들과는 I/O 포트라고 불리는 소수의 특별한 레지스터를 통해 데이터를 주고받는다.
- 메모리 매핑된 직렬 포트를 통해 긴 바이트의 열을 전송하려고 하면 CPU는 전송할 한 바이트를 데이터 레지스터에 쓰고, 이 바이트가 출력 가능하다는 것을 제어 레지스터의 한 비트를 설정함으로써 알려준다. 장치는 이 바이트를 가져가고, 제어 레지스터의 그 비트를 끔으로써 다음 바이트 전송이 준비되었음을 알려준다. CPU는 이제 다음 바이트를 전송할 수 있다.
-  CPU가 제어 비트 값을 확인하기 위해 폴링(계속적으로 루프를 돌면서 장치가 준비 상태로 들어가는지 확인 하는 것) 방식을 사용하면 이러한 일련의 과정을 프로그램식 I/O(PIO)라고 한다. CPU가 폴링하지 않고 장치가 준비되었을 때 인터럽트를 받는 경우는 인터럽트 구동형이라고 부른다.

## 커널 메모리의 할당
- 사용자 모드에서 실행 중인 프로세스가 추가적인 메모리를 요구하면 커널이 관리하는 가용 페이지 프레임에서 페이지가 할당된다.
- 가용 리스트는 페이지 교체 정책에 의해 물리 메모리에 여기 저기 흩어져 있는 페이지들로 채워진다. 사용자 프로세스가 오직 한 바이트만을 필요로 하는 경우라면 프로세스가 한 페이지 프레임을 할당받았으므로 내부 단편화가 발생한다.
- 그러나 커널 메모리는 보통 사용자 모드 프로세스에게 할당해 주기 위한 페이지 리스트와는 별도의 메모리 풀에서 할당받는다. 
- 이렇게 하는 2가지 이유가 있다. 커널은 다양한 크기의 자료 구조를 위해 메모리를 할당받는다. 이 자료 구조들은 페이지 크기보다 작은 크기를 갖기도 한다. 결과적으로 커널은 메모리 사용을 절재해야 하며, 단편화에 의한 낭비를 최소화하고자 한다. 많은 OS들이 커널 코드나 데이터를 페이징하지 않기 때문에 특히 더 중요하다, 그 다음은 사용자 모드 프로세스에 할당되는 페이지들은 물리 메모리 상에서 굳이 연속될 필요는 없다. 그러나 가상 메모리 인터페이스를 통하지 않고 물리 메모리에 직접 접근하는 특정 하드웨어 장치는 물리적으로 연속적인 메모리를 필요로 하는 경우가 있다.

### 버디 시스템
- 이 시스템은 물리적으로 연속된 페이지들로 이루어진 고정된 크기의 세그먼트로부터 메모리를 할당한다. 메모리는 이 세그먼트로부터 2의 거듭제곱 할당기에 의해 2의 거듭제곱 단위로 할당된다. 2의 거듭제곱 크기가 아닌 메모리 요구는 가장 가까운 2의 거듭제곱 크기로 올림된다.
- 버디 시스템의 이점중 하나는 병합이라고 부르는 과정을 통해 서로 인접한 버디들이 손쉽게 하나의 큰 세그먼트로 합쳐질 수 있다는 점이다.
- 버디 시스템의 단점은 가장 가까운 2의 거듭제곱으로 올려서 할당하기 때문에 세그먼트 내의 단편화를 가져온다는 것이다.

### 슬랩 할당
- 슬랩은 하나 또는 그 이상의 연속된 페이지들로 구성된다. 캐시는 하나 혹은 그 이상의 슬랩들로 구성된다. 
- 각 커널 자료 구조마다 하나의 캐시가 존재한다. 예를 들어, 프로세스 설명자를 위한 캐시, 파일 객체를 위한 캐시, 세마포어를 위한 캐시등이 존재한다.
- 각 캐시는 커널 자료 구조의 인스턴스로 생성된 객체들로 채워져 있다. 예를 들면, 세마포어를 위한 캐시는 세마포어 객체들이 저장되며, 프로세스 기술자를 위한 캐시는 프로세스 기술자 객체로 채워져 있다. 각 객체는 해당 캐시에 저장된다.
- 슬랩 할당 알고리즘은 커널 객체를 저장하기 위해 캐시를 사용한다. 캐시가 생성되면 초기에는 free라고 표시된 몇 개의 객체들이 캐시에 할당된다. 캐시 내 객체의 수는 해당 슬랩의 크기에 좌우한다. 커널 자료 구조를 위한 객체가 필요하면 free 객체들 중 하나를 캐시로부터 할당해 준다. 할당된 객체는 used라고 표시한다.
- Linux 시스템에서 프로세스 기술자는 `struct task_struct` 자료 구조로 표현되면 대략 1.7KB 정도를 필요로 한다. Linux 커널이 새로운 프로세스를 생성할 때 캐시로부터 `struct task_struct` 객체를 위한 메모리를 요청한다. 캐시는 요청을 처리하기 위해 이미 슬랩에 할당되어 있던 free로 표시된 `struct task_struct` 객체를 사용한다.
- Linux에서 슬랩은 Full 슬랩 내의 모든 객체가 used로 표시되거나 Empty 슬랩 내의 모든 객체가 free로 표시되거나 Partial used/ free 객체가 섞여 있는 상태들이 존재한다.
- 슬랩 할당기는 먼저 Partial 슬랩의 free 객체를 이용해 요청을 처리하려고 시도한다. Partial 슬랩이 없으면 Empty 슬랩으로부터 free 객체를 할당한다. Empty 슬랩도 없는 경우에는 새로운 슬랩이 연속된 물리 메모리에서 할당되어 캐시에 주어진다. 객체는 이 슬랩에서 할당된다.
- 슬랩할당기는 두가지 장점이 있다. 하나는 단편화에 의해 낭비되는 메모리가 없다. 각 고유한 커널 자료 구조가 연관된 캐시를 갖고, 각 캐시는 하나 이상의 슬랩으로 구성되며, 이 슬랩은 객체의 크기로 나눠지기 때문에 단편화는 문제가 되지 않는다. 따라서 커널이 객체를 위한 메모리를 요구할 때마다 슬랩 할당기는 정확히 필요한 만큼의 메모리만을 할당한다. 나머지 하나는 메모리 요청이 빠르게 처리된다. 따라서 슬랩 할당기는 객체의 할당과 해제가 빈번한 경우, 메모리를 관리하는데 특히 효율적이다. 커널로부터 오는 요청은 대부분 이러한 특징을 보인다. 메모리 할당과 해제는 상당한 시간이 소요될 수 있다. 그러나 객체들은 미리 생성되어 있고, 따라서 캐시에서 쉽게 할당이 가능하다. 게다가 커널이 특정 객체를 다 사용하고 해제하면 free로 표시된 상태로 캐시로 반환되어 다음 요구 시 즉시 할당 가능하게 된다.
- 리눅스와 솔라리스에서도 버디 시스템보다 슬랩 할당기를 채택하고 있다.

## 기타 고려 사항

### 프리페이징
- 순수 요구 페이징 시스템은 프로세스가 시작될 때 많은 페이지 부재를 발생한다. 이것은 최초의 지역을 메모리로 올릴 때 생기는 현상이지만 다른 때에도 발생할 수 있다. 예를 들면 스왑 아웃되었던 프로세스가 다시 시작될 때 그 프로세스의 모든 페이지는 디스크에 존재하고, 각 페이지는 페이지 부재를 발생시키면서 다시 메모리 들어와야 한다.
- 프리페이징은 과도한 초기 페이징을 방지하기 위한 기법으로 필요하게 될 모든 페이지를 한꺼번에 메모리로 가져오는 기법이다. 솔라리스 같은 경우는 작은 파일들에 대한 페이지를 프리페이징한다. 
- 예를 들어, 작업 집합을 사용하는 시스템에서는 각 프로세스마다 작업 집합에 속한 페이지 리스트들을 가지고 있다. 어떤 프로세스를 보류시켜야 한다면 그 프로세스의 작업 집합을 기억해 놓는다. 그 프로세스가 다시 실행을 시작할 예정이라면 그 프로세스를 재시작시키기 전에 작업 집합을 모두 메모리에 올려놓는다.
- 프리페이징은 어떤 경우에도 이득을 준다. 논점은 프리페이징을 사용하는 비용이 해당 페이지 부재를 처리하는 비용보다 적은가 하는 것이다. 프리페이징하여 메모리로 가져올 페이지의 대부분이 사용되지 않는 경우가 대부분이다.

### 페이지 크기
- 페이지 크기를 결정하는 데에 한 가지 관심 사항은 페이지 테이블의 크기이다. 주어진 가상 메모리 공간에서 페이지 크기를 감소시키는 것은 페이지의 수를 증가시키고, 결국 페이지 테이블의 크기를 증가시킨다.
- 모든 활성 프로세스는 각자의 페이지 테이블을 유지해야 하므로, 큰 페이지가 좋다. 그러나 메모리의 이용률을 위해서는 작은 페이지가 좋다. 
- 페이지 경계에 딱 맞춰 메모리가 할당되지 않을 수 있다 따라서 마지막 페이지의 일부는 할당되어야 하지만 일부는 사용되지 않을 것이다. 프로세스 크기와 페이지 크기가 독립적이라고 가정하면, 평균적으로 각 프로세스의 마지막 페이지의 절반가량이 낭비된다고 기대할 수 있다. 내부적 단편화를 최소화하기 위해서는 작은 페이지의 크기가 좋다.
- 또 다른 문제는 페이지를 읽거나 기록하는 데 요구되는 디스크 시간이다. 입출력 시간은 탐색시간, 회전 지연 그리고 전송 시간으로 구성된다. 전송 시간은 전송량에 비례한다. 이것만 생각하면 작은 크기의 페이지가 유리하다고 할 수 있다. 그러나 지연시간이나 탐색시간이 전송 시간보다는 훨씬 큰 비중을 차지한다. 디스크 입출력 시간을 줄이기 위해서는 큰 크기의 페이지가 유리하다.
- 페이지 크기가 작으면 지역성이 향상되어 전체 I/O는 더 줄어들 것이다. 작은 페이지를 사용하면 각 페이지가 프로그램의 지역에 보다 일치할 수 있다. 반대로 작은 페이지를 사용하면 정밀도가 좋아져서 실제 사용될 메모리만 부리하는 것이 가능하다. 큰 페이지를 사용하면 꼭 필요한 내용뿐 아니라 필요 여부와는 무관하게 우연히 같은 페이지에 속하게 된 모든 정보들도 함께 올라오게 된다. 따라서 작은 크기의 페이지가 적은 횟수의 I/O를 실행하고, 할당된 메모리 총량도 적게 된다.
- 페이지 크기가 작게 되면 매 바이트 접근마다 모두 페이지 부재가 발생할 가능성이 커진다. 페이지 부재가 발생하면 인터럽트 처리, 레지스터 상태 저장, 페이지 교체, 페이징 장치에 대한 큐잉, 테이블 갱신 등 많은 오버헤드를 유발시킨다. 따라서 페이지 부재 횟수를 줄이기 위해서는 큰 크기의 페이지가 좋다. 
- 내부 단편화나 지역성 같은 요소를 생각하면 작은 페이지가, 반면 나머지들을 생각하면 페이지 크기가 큰 것이 좋다. 그러나 시대적으로 페이지 크기가 커져 가는 추세이다.

### TLB 범위
- TLB 적중률은 전체 가상 메모리 참조 중 페이지 테이블을 접근하지 않더라도, TLB 상에서 주소 변환을 실행할 수 있는 경우의 비율을 말한다. 적중률은 TLB의 항목 수와 관련 있다. TLB 항목의 개수를 늘리면 적중률은 높아지게 된다. TLB에 사용되는 연관 메모리 자체가 비싸고 전력도 많이 소모하기 때문에 TLB의 크기를 늘리는 일은 쉬운 일이 아니다.
- 적중률과 연관된 잣대로는 TLB 범위라는 것이 있다. TLB 범위는 TLB로부터 액세스할 수 있는 메모리의 양을 뜻한다. 이 값은 TLB에 있는 항목 수에 페이지 크기를 곱한 것이다. 
- 이상적으로는 한 프로세스의 작업 집합이 TLB에 다 들어올 수 있어야 가장 좋다. 그러지 않으면 프로세스는 메모리 참조를 TLB에서 해결하지 못하고 페이지 테이블을 통해서 해결하느라 매우 많은 시간을 소모하게 된다. TLB 크기를 두 배로 늘리면 TLB 범위도 두 배 늘어난다. 그러나 메모리를 많이 필요하는 프로세스의 경우에는 이것도 부족할 수 있다.
- TLB 범위를 늘릴 수 있는 다른 방도는 페이지 크기를 늘리든가 또는 여러 페이지 크기를 허용하는 것이다. 그러나 큰 페이지를 필요로 하지 않는 애플리케이션에서는 단편화가 증가할 수 있다. 다른 방법으로는 OS가 여러 페이지 크기를 허용하는 방법이 있을 수 있다.
- 여러 크기의 페이지를 지원하기 위해서는 OS가 TLB를 관리해야 한다. 예를 들어, TLB 내의 한 필드는 그 항목에 대응하는 페이지 프레임의 크기를 나타내야 한다. TLB 관리를 하드웨어로 하지 않고 소프트웨어로 하게 되면 성능이 떨어지게 된다. 그러나 이 감소는 적중률과 TLB 범위의 향상으로 상쇄될 수 있다. 
- 최근의 추세는 TLB 관리를 소프트웨어로 하면서, OS가 다양한 페이지 크기를 지원하는 방향으로 가고 있다.

### 역 페이지 테이블
- 이 페이지 관리 형태의 목적은 가상대-물리 주소 변환을 추적하는데 필요한 물리 메모리의 양의 줄이는 것이다. 물리 메모리 페이지마다 한 개의 항목을 갖고, `<process-id, page-number>`의 쌍으로 인덱스되는 테이블을 사용하여 달성한다.
- 각 페이지 프레임에 어떤 가상 메모리 페이지가 저장되어 있는지의 정보를 유지하기 때문에 역 페이지 테이블은 이 정보를 저장하는데 필요한 물리 메모리양을 줄인다. 그렇지만 역 페이지 테이블은 프로세스의 전체 논리 주소 공간에 대한 정보를 더 이상 유지 하지 않고, 참조된 페이지가 현재 메모리에 없을 때에는 이 정보가 필요하다. 요구 페이징은 이 정보가 있어야 페이지 부재를 처리할 수 있다. 이 정보를 공급하기 위해서는 프로세스 당 하나씩 외부 페이지 테이블을 유지해야 한다. 이 테이블은 프로세스마다 하나씩 있던 전통적인 페이지 테이블과 유사하고, 각 가상 페이지의 위치정보를 갖고 있다.
- 외부 테이블은 단지 페이지 부재 시에만 참조되기 때문에 빨리 제공되어야 할 필요가 없다. 대신 외부 테이블은 필요에 따라 그 자체가 페이징될 수도 있다. 이때 페이지 부재 처리 과정에서 외부 페이지 테이블 읽어 들이기 위해 또 다른 페이지 부재를 발생시킬 수 있다.

### 프로그램 구조
- 사용자나 컴파일러가 요구 페이징의 특성을 이해하면 성능을 개선시킬 수도 있다.

```cpp
int i,j;
int[128][128] data;

for(j=0; j<128; ++j)
	for(i=0; i<128; ++i)
		data[i][j] = 0;
```

- 페이지 크기가 128워드라고 가정하고 128*128 배열을 초기화 시킨다고 한다. 배열은 행 중심으로 저장된다. 페이지가 128워드 크기이므로 각 행은 한 페이지를 점유하게 된다. 그러면 프로그램은 각 페이지에서 한 워드를 0으로 만들고, 그 다음 각 페이지에서 또 다른 워드를 0으로 만드는 과정을 반복한다. OS가 이 프로그램에게 128 프레임보다 적은 프레임을 할당한다면, 모두 128 * 128번의 페이지 부재를 초래하게 된다.

```cpp
int i,j;
int[128][128] data;

for(i=0; i<128; ++i)
	for(j=0; j<128; ++j)
		data[i][j] = 0;
```

- 대조적으로 이 프로그램은 한 페이지에 있는 모든 워드를 0으로 한 다음 새 페이지로 옮기게 되므로 페이지 부재의 수를 128로 감소시킬 수 있다.
- 자료구조와 프로그래밍 구조를 잘 선택하면 지역성을 향상시킬 수 있고, 페이지 부재율과 작업 집합의 페이지 수를 줄일 수 있다. 예를 들어 스택은 항상 탑에서만 참조되므로 지역성이 높다. 반면, 해시 테이블은 참조를 분산시키므로 지역성이 나쁘다. 물론, 참조 지역성은 자료구조 사용의 효율을 측정하는 한 요소일 뿐이다. 그밖에 매우 중요한 요소들에는 탐색 속도, 총 메모리 참조 회수, 접근한 총 페이지 개수 등이 있다.
- 컴파일러와 적재기도 페이징에 중요한 영향을 줄수 있다. 코드와 데이터를 분리하고 재진입 가능 코드를 생성하면, 코드 페이지는 읽기 전용이 되어 절대 변경되지 않게 한다. 변경되지 않은 페이지는 교체 시 페이지 아웃되지 않아도 된다.
- 적재기는 하나의 루틴을 페이지 경계에 걸치지 않도록 할당하여 각 루틴이 한 페이지 내에 완전히 들어가도록 할 수 있다. 서로 호출하는 빈도수가 잦은 루틴들은 서로 같은 페이지에 위치시킬 수 있다. 이러한 묶음 작업은 bin-packing 문제의 일종으로 볼 수 있다. 가변 크기의 적재 세그먼트들을 균일한 크기의 페이지들로 묶으면서 페이지 간 참조가 최소화되도록 하는 것이다. 이러한 방법은 큰 페이지 크기를 갖는 경우에 유용하다.

### 입출력 상호 잠금(I/O Interlock)
- 요구 페이징을 사용할 때 페이지 중 일부는 메모리에 붙박이로 고정시키는 것이 필요할 때가 있다. 한 가지 그런 상황은 입출력이 사용자 (가상)메모리를 대상으로 이루어질때 발생한다. 입출력은 흔히 별도의 입출력 처리기(I/O channel)에 의해서 구현된다.
- 어떤 프로세스가 입출력 요구를 하고 입출력장치의 큐에 들어간다 그동안 CPU는 다른 프로세스들에게 할당된다. 그런데 이 프로세스들이 페이지 부재를 일으키고, 그들 중 하나가 전역 교체 알고리즘을 사용하여 대기 중인 프로세스의 메모리 버퍼를 포함하고 있는 페이지를 교체한다. 그 페이지는 페이지 아웃된다. 얼마후 I/O 요청이 큐의 맨 앞으로 이동하고, 지정된 주소를 대상으로 I/O 작업이 일어난다. 그러나 원래 버퍼가 있던 프레임은 미미 다른 프로세스에 의해 사용되고 있다. 이러한 사건이 일어나서는 안된다.
- 문제의 해결책은 일반적으로 두 가지 방법이 있다. 한 가지 해결책은 사용자 공간에는 입출력을 하지 않는 것이다. 실제 입출력은 항상 시스템 메모리와 입출력장치 사이에서만 행해지고 그 후에 시스템 메모리와 사용자 메모리 사이에서 데이터 복사된다. 디스크에 어떤 블록을 쓰고 싶으면 먼저 시스템 메모리로 복사하고 거기서 디스크에 쓰기 작업을 실행해야 한다. 이 추가의 복사는 허용할 수 없는 큰 오버헤드를 유발시킬 수 있다.
- 또 다른 해결책은 페이지를 메모리에 잠금하는 것이다. 잠금 비트를 각 프레임마다 두고 만약 프레임이 잠금되면 그것은 교체 고려 대상에서 제외된다. 이러한 방식에서는 테이프에 블록을 쓰기 위해서는 해당 블록을 담고 있는 페이지를 일단 잠가야 한다. 그런 후에 시스템은 예전처럼 실행을 계속할 수 있다. 입출력이 완료될 때 그 페이지의 잠금은 해제된다.
- 잠금 비트는 다양한 상황에서 사용된다. 종종 OS 핵심인 커널 전부 또는 일부가 메모리에 잠금된다. 대부분의 OS가 커널에서 발생하는 페이지 부재를 제대로 처리할 수 없기 때문이다.
- 잠금 비트는 정상적인 페이지 교체 시에도 사용된다. 우선순위가 낮은 프로세스가 페이지 부재를 발생시킨다. 페이징 시스템은 교체 프레임을 선택하여 필요한 페이지를 메모리로 읽어 들인다. 실행을 계속할 수 있는 준비가 되어있으므로 이 우선순위가 낮은 프로세스는 준비완료 큐에 들어가 CPU를 기다리게 된다. 우선순위가 낮기 때문에 이 프로세스는 한동안 CPU를 사용하지 못할 수 있다. 우선순위가 낮은 프로세스가 기다리는 동안 우선순위가 높은 프로세스가 페이지 부재를 일으킨다. 교체할 페이지를 찾다가 한번도 참조되거나 변경되지 않은 프레임을 발견한다. 사실 이 페이지는 우선순위가 낮은 프로세스가 방금 읽어 들인 페이지이다. 외견상으로는 이 페이지는 변경되지 않았기 때문에 쓰기 작업이 필요하지 않고 오랫동안 접근되지도 않은 것처럼 보여서 가장 완벽한 교체 대상으로 보인다.
- 높은 우선순위의 프로세스가 낮은 우선순위 프로세스의 페이지를 교체할 수 있는냐 하는 것은 정책적인 선택사항이다. 결국, 이 경우는 높은 우선순위 프로세스를 위해 낮은 우선순위 프로세스의 실행을 지연시킨 것이다. 그러나 낮은 우선순위 프로세스의 페이지를 읽어 들이기 위한 노력과 자원을 소모하였다. 최소한 한 번이라도 사용될 때까지 새롭게 읽어 들인 페이지를 교체하지 못하도록 하기 위해 잠금 비트를 이용하여 구현할 수 있다. 페이지가 교체 페이지로 선택되면 잠금 비트를 켠다. 부재를 발생시킨 프로세스가 다시 실행될 때까지 남아 있게 된다.
- 잠금 비트 사용이 위험한 상황을 만들 수 있다. 잠금 비트는 일단 1로 설정되고 나서 절대로 꺼지지 않을 수 있다. 이런 상황이 일어나면 잠금도니 프레임은 영원히 사용할 수 없게 된다. 단일 사용자 시스템에서는 잠금의 과용이 잠금을 사용한 사용자 자신에게만 피해를 준다. 다중 사용자 시스템에서는 사용자에 대한 신뢰도를 낮추어야 한다.
- 실시간 처리의 경우는 가상 기억장치가 페이지 부재 처리로 긴 지연 시간 초래가능하다. 실시간과는 가상기억 장치가 상극이다.

## 운영체제의 예

### Windows XP
- 클러스터링 방식을 결합한 요구 페이징 가상 메모리를 구현한다. 클러스터링에서는 페이지 부재가 발생하면 그 페이지뿐만 아니라 그 페이지 다음에 위치한 여러 페이지들도 함께 가져온다. 
- 프로세스는 처음 생성될 때 작업 집합의 상한과 하한이 설정된다. 하한이란 그 프로세스 메모리에 유지할 수 잇는 시스템이 보장하는 최소한의 페이지 개수를 의미한다. 메모리 공간이 넉넉하면 이보다도 더 줄 수가 있으며, 상한까지 할당할 수 있다.
- 가상 메모리 관리자는 가용 공간의 리스트를 가지고 있다. 이 리스트와 시스템이 유지하는 임계치를 비교하여 현재 상황이 메모리가 넉넉한 상황인지 아닌지 판정한다. 프로세스가 페이지 부재를 일으켰는데 그 프로세스가 상한치보다 적게 메모리를 가지고 있으면 메모리를 더 할당한다. 그러나 이미 상한치까지 꽉 채워서 메모리를 가지고 있는 상태에서 페이지 부재를 일으키면, 그 프로세스가 이미 가지고 있는 페이지들을 대상으로 지역 교체 정책을 적용한다.
- 시스템 전체적으로 가용 공간이 임계치보다 낮아지면 시스템은 자동 작업 집합 조절 전술을 써서 임계치 이상의 가용공간을 확보한다. 이 정책은 각 프로세스마다 할당되어 있는 페이지 수를 점검하고, 하한치보다 넘게 할당된 페이지들이 있으면 FIFO 알고리즘을 써서 하한치에 내려갈 때까지 페이지를 회수한다. 이렇게 해서 충분한 가용 공간을 시스템이 확보하면, 할당된 메모리가 하한치에 도달한 프로세스에게 가용 페이지들을 할당해 준다.
- 작업 집합에서 어떤 페이지를 교체할 것인지 판단하는 것은 처리기 구조에 따라 다르게 구현된다.

### Solaris
- 스레드가 페이지 부재를 일으키면 커널은 자신이 관리하고 있는 가용 페이지 리스트로부터 한 페이지를 확보해 할당해 준다. 따라서 OS 커널은 항상 충분한 가용 공간을 확보하고 있어야 한다. 가용 페이지 리스트에는 lotsfree 파라미터가 지정되고, 이것은 페이징을 시작하는 임계치가 된다. 커널은 매 초당 네 차례씩 가용 공간의 크기가 lotsfree보다 작은지 점검한다.
- 가용 공간의 크기가 그보다 적어지면 pageout이라는 프로세스를 가동시킨다. pageout 프로세스는 페이지 스캔을 위해 2개의 시계 바늘을 사용한다는 것을 제외하면 2차 기회 알고리즘과 유사하다. 
- pageout 프로세스는 다음과 같이 동작한다. 앞쪽 바늘이 일차로 모든 페이지를 돌며 참조 비트를 0으로 만든다. 이후 시계의 뒤쪽 바늘이 다시 모든 페이지를 점검하며, 그 때까지 아직 참조 비트가 0인 페이지를 가용 공간으로 회수시킨다. 이때 페이지의 내용이 변경된 경우는 디스크에 기록한다.
- Solaris는 해제되었으나 아직은 덮어 쓰이지 않은 페이지들의 캐시 리스트를 관리한다. 가용 리스트는 무효한 내용을 담고 있는 프레임들을 포함한다. 캐시 리스트의 페이지가 가용 리스트로 옮겨지기 전에 접근되는 경우 페이지는 재할당된다.
- pageout 알고리즘은 페이지가 스캔되는 횟수(scanrate)를 조절하기 위해서 몇 개의 파라미터를 가지고 있다. scanrate는 초당 페이지 수로 정의되며, slowscan부터 fastscan 범위의 값을 가진다. 가용 공간의 크기가 lotsfree보다 적게 되면 초당 slowscan 페이지 속도로 스캔한다. 가용 공간의 양에 따라 이 횟수는 fastscan까지 증가한다.
- 두 바늘 사이의 페이지 수는 handspread라는 시스템 변수에 의해 결정된다. 앞바능이 참조 비트를 해제하는 것과 뒷바늘이 참조 비트 값을 조사하는 것 사이의 시간은 sacnrate와 handspread에 따라 결정된다.
- 가용 공간이 desfree보다 적으면 최소한 desfree만큼의 유지하려고 한다. 그러나 유지하지 못하면 커널은 프로세스들을 스와핑하기 시작한다. 즉, 스왑되는 프로세스에게 할당되었던 모든 페이지를 가용하게 만든다. 일반적으로 커널은 오랫동안 유휴상태에 있던 프로세스들을 찾는다. 커널이 가용공간을 minfree 이상 유지 못하면 새 페이지를 달라는 요청이 있을 때마다 pageout 프로세스를 실행시킨다.
- 최근 Solaris 커널의 페이징 알고리즘은 개선되었는데, 한 가지는 공유 라이브러리의 페이지들을 인식하다는 것이다. 여러 프로세스에 의해 공유되고 있는 라이브러리의 페이지는 scanner에 의해 선택될 수 있는 상황이라 하더라도 페이지 스캔 과정에서 제외된다. 다른 개선사항은 프로세스에 할당된 페이지와 일반 파일에 할당된 페이지를 구분해 처리한다는 것이다. 이것을 `우선순위 페이징`이라 한다.
