## HDFS(Hadoop Distributed File System)
- 대용량 파일을 분산된 서버에 저장하고, 많은 클라이언트가 저장된 데이터를 빠르게 처리할 수 있게 설계된 파일 시스템이다.

### 기존 대용량 파일 시스템
- DAS : 서버에 직접 연결된 스토리지이며, 외장형 하드디스크이다. 여러개의 하드디스크를 장착할 수 있는 외장 케이스를 이용하는 방식
- NAS : 일종의 파일 서버, 별도의 운영체제를 사용하며, 파일 시스템을 안정적으로 공유할수 있다. 주로 첨부파일이나 이미지 같은 데이터를 저장하는데 많이 사용
- SAN : 수십~수백대의 SAN 스토리지를 데이터 서버에 연결해 총괄적으로 관리해주는 네트워크를 의미, DBMS와 같이 안정적이고 빠른 접근이 필요한 데이터를 저장하는데 사용

### 기존 시스템과의 차이점
- 저사양 서버를 이용해 스토리지를 구성할수 있다는것.
- HDFS에 저장하는 데이터는 물리적으로는 분산된 서버의 로킬 디스크에 저장되어 있지만, 파일 읽기 및 저장과 같은 제어는 HDFS에서 제공하는 API를 이용해 처리된다.
- 트랜잭션이 중요한 경우는 HDFS는 적합하지 않고 대규모 데이터를 저장하거나, 배치로 처리를 하는 경우에 이용된다.

### HDFS 4가지 목표
- 장애복구 : 장애를 빠른 시간에 감지하고 대처할수 있게 설계되었다. 데이터를 저장하면, 복제 데이터도 함께 저장되어 데이터 유실을 방지한다. 분산 서버 간에는 주기적으로 상태를 체크해 빠른 시간에 장애를 인지하고, 대처할 수 있게 도와줍니다.
- 스트리밍 방식의 데이터 접근 : HDFS는 클라이언트의 요청을 빠른 시간 내에 처리하는 것보다는 동일한 시간내에 더 많은 데이터를 처리하는 것을 목표로 합니다. 이래서, 랜덤 방식의 데이터 접근을 고려하지 않습니다. HDFS는 랜덤 접근 방식 대신 스트리밍 방식으로 데이터에 접근하도록 설계되어 있습니다. 그래서 클라이언트는 끊김없이 연속된 흐름으로 데이터에 접근할 수 있습니다.
- 대용량 데이터 저장 : HDFS는 하나의 파일이 기가바이트 이상의 크기로 저장될 수 있게 설계되었다. 높은 데이터 전송 대역폭과 하나의 클러스터에서 수백 대의 노드를 지원할 수 있습니다. 또한 하나의 인스턴스에서는 수백만개 이상의 파일을 지원한다.
- 데이터 무결성 : HDFS에서는 한 번 저장한 데이터는 더는 수정할 수 없고, 읽기만 가능하게 해서 데이터 무결성을 유지한다.

### 아키텍쳐
#### 블록 구조 파일 시스템
- HDFS에 저장하는 파일은 특정 크기의 블록으로 나눠져 분산된 서버에 저장됩니다.
- 블록 크기는 기본적으로 64MB로 설정되어 있고, 변경된다.
- 블록의 크기의 사이즈가 64MB인 이유는 디스크 시크 타임의 감소이며, 네임노드가 유지하는 메타데이터의 크기 감소를 위함이며, 클아이언트와 네임노드의 통신 감소를 위함이다.
- HDFS는 블록을 저장할 때 기본적으로 3개씩 블록의 복제본을 저장한다.

#### 네임노드와 데이터노드
- HDFS는 마스터-슬레이브 아키텍쳐이다.
- 마스터 서버는 네임노드이고, 슬레이브 서버는 데이터노드이다.
- 네임노드는 메타데이터 관리, 데이터노드 모니터링, 블록관리, 클라이언트 요청 접수를 실행한다.
- 메타데이터 관리 : 파일 시스템을 유지하기 위한 메타데이터를 관리한다, 메타데이터는 파일 시스템 이미지(파일명, 디렉터리등)와 파일 대한 블록 매핑 정보로 구성된다, 네임노드는 클라이언트에게 빠르게 응답할 수 있게 메모리에 전체 메타데이터를 로딩해서 관리한다.
- 데이터노드 모니터링 : 데이터노드는 네임노드에게 3초마다 하트비트 메세지를 전송한다. 하트비트는 데이터노드 상태 정보와 데이터노드에 저장되어 있는 블록의 목록으로 구성된다. 네임노드는 하트비트를 이용해 데이터노드의 실행 상태와 용량을 모니터링 한다. 일정기간 하트비트를 전송하지 않는 데이터노드가 있으면 장애가 발생한 서버로 판단한다.
- 블록관리 : 장애가 발생한 데이터노드를 발견하면 해당 데이터노드의 블록을 새로운 데이터노드로 복제한다. 또한 용량이 부족한 데이터 노드가 있으면 용량에 여유가 있는 데이터 노드로 블록을 이동시킨다. 블록의 복제본 수도 관리한다. 만약 복제본 수와 일치하지 않는 블록이 발견될 경우 추가로 블록을 복제하거나 삭제해준다.
- 클라이언츠 요청 접수 : HDFS에 클라이언트가 접근하려면 반드시 네임노드에 먼저 접속해야한다. HDFS에 파일을 저장하는 경우 기존 파일의 저장여부와 권한확인의 절차를 거쳐서 저장을 승인한다.
- 데이터노드는 클라이언트가 HDFS에 저장하는 파일을 로컬 디스크에 유지한다. 로컬에 저장되는 파일은 실제 데이터가 저장되어있는 로우 데이터와 체크섬이나 파일 생성 일자같은 메타데이터가 설정되어 있는 파일이다.

#### 파일 저장 - 요청
- 클라이언트가 HDFS에 파일을 저장하는 경우 파일을 저장하기 위한 스트림을 생성해야 한다.
- 하둡은 `FileSystem`이라는 추상 클래스에 일반적인 파일 시스템을 관리하기 위한 메서드를 정의한다.
- HDFS에 파일을 저장하는 경우에는 파일 시스템 클래스중 `DistributedFileSystem`을 사용한다.
- 네임노드는 클라이언트의 요청이 유효한지 검사한다. 이미 생성된 파일이나, 권한 문제등이 있다면 오류가 발생한다. 파일 유효성 검사 결과가 정상일 경우 파일 시스템 이미지에 해당 파일의 엔트리를 추가한다. 마지막으로 네임노드는 클라이언트에게 해당 파일을 저장할 수 있는 제어권을 부여한다.

#### 파일 저장 - 패킷 전송
- 클라이언트가 제어권을 얻게 되면 파일을 네임노드에게 전송하지 않고 각 데이터 노드에 전송한다. 그리고 저장할 파일은 패킷 단위로 나눠서 전송한다.
- `DFSOutputStream`은 클라이언트가 저장하는 파일을 64k 크기의 패킷으로 분할한다.
- `DFSOutputStream`은 전송할 패킷을 내부 데이터큐에 등록한다.
- 네임노드는 `DataStreamer`에게 블록을 저장할 데이터노드 목록을 반환한다. 이 목록은 복제본 수와 동일한 수의 데이터노드를 연결한 파이프라인을 형성한다.
- `DataStreamer`는 파이프라인의 첫 번째 데이터노드부터 패킷 전송을 시작한다. 데이터노드는 클라이언트와 다른 데이터노드로부터 패킷을 주고받기 위해 `DataXceiverServer` 데몬을 실행한다. 이것은 클라이언트 및 다른 데이터노드와 패킷 교환 기능을 제공한다.
- 첫번째 데이터노드에 패킷을 저장할때 `DFSOutputStream`은 내부 큐인 승인큐에 패킷을 등록한다. 승인큐는 패킷 전송이 완료되었다는 응답을 기다리는 패킷이 등록되어 있으며, 모든 데이터노드로부터 응답을 받았을때만 해당 패킷이 제거된다.
- 각 데이터노드는 패킷이 정상적으로 저장되면 자신에게 패킷을 전송한 데이터노드에게 ACK 메세지를 전송한다.
- 각 데이터는 패킷 저장이 완료되면 네임노드의 `blockReceived` 메서드를 호출한다. 이를 통해 네임노드는 해당 블록이 정상적으로 저장되었다는 것을 인지한다.
- `DFSOutputStream`의 내부 스레드인 `ResponseProcessor`는 파이프라인에 있는 모든 데이터노드로부터 승인 메시지를 받으면 해당 패킷을 승인큐에서 제거한다.
- 만약 패킷 전송중 장애가 발생하면 승인 큐에 있는 모든 패킷을 데이터큐로 이동한다. 네임노드에게서 장애가 발생한 데이터노드가 제거된 새로운 데이터 목록을 내려받는다.
- 마지막으로 새로운 파이프라인을 생성후 다시 패킷 전송 작업을 시작한다.

#### 파일 저장 - 파일 닫기
- `DistributedFileSystem`은 `DFSOutputStream`의 close()를 호출하고 남은 모든 패킷을 플러시한다.
- `DFSOutputStream`는 네임노드의 메서드를 호출해 패킷이 정상적으로 저장되었는지 확인한다. 네임노드의 최소 블록 복제본 수만 저장되었다면 true를 반환한다.

#### 파일 읽기 - 파일 조회 요청
- 클라이언트는 입력 스크림 객체를 이용해 HDFS에 저장된 파일을 조회할 수 있다.
- `DFSInputStream`은 네임노드의 메서드를 호출하여 조회 대상 파일의 블록 위치 정보를 조회한다. `DFSInputStream`은 한번에 모든 블록을 조회하지 않고, 기본 블록 크기의 10배수만큼 블록을 조회한다.
- 네임노드는 조회 대상 파일의 블록 위치 목록을 생성후 목록을 클라이언트에 가까운 순으로 정렬한다. 정렬이 완료되면 정렬된 블록 위치 목록을 반환한다.

#### 파일 저장 - 블록 조회
- 클라이언트는 입력 스트림 객체를 통하여 스트림 조회를 요청한다.
- `DFSInputStream`은 첫 번째 블록과 가장 가까운 데이터노드를 조회한 후, 해당 블록을 조회하기 위한 리더기를 생성한다.
- 데이터노드의 `DataXceiverServer`가 블록을 `DFSInputStream`에게 반환한다.
- `DFSInputStream`은 조회한 데이터의 체크섬을 검증하고 문제가 있을 경우 다른 데이터노드에게 블록 조회 요청한다.
- `DFSInputStream`은 파일을 모두 읽을 때까지 계속해서 블록을 조회한다. 만약 `DFSInputStream`이 저장하고 있던 블록을 모두 읽었는데도 파일을 모두 일지 못했다면 네임노드의 메소드를 호출해 필요한 블록 위치 정보를 다시 요청한다.
- 위와 같이 파일을 끊김없이 연속적으로 읽기 때문에 클라이언트는 스트리밍 데이터를 읽는 것처럼 처리할 수 있다.
- 네임노드는 `DFSInputStream`에게 클라이언트에게 가까운 순으로 정렬된 블록 위치 반환

#### 파일 저장 - 입력 스트림 닫기
- 클라이언트는 입력 스트림 객체의 메서드를 요청해 스트림 닫기를 요청
- `DFSInputStream`은 데이터노드와 연결되어 있는 커넥션을 종료한다.

#### 네임노드가 구동될 경우, `editslog`와 `fsimage` 파일 사용
- 네임노드가 구동되면 로컬에 저장된 `editslog`와 `fsimage`를 조회
- 메모리에 `fsimage`를 로딩해 파일 시스템 이미지를 생성
- 메모리에 로딩된 파일 시스템 이미지에 `editslog`에 기록된 변경 이력을 적용
- 메모리에 로딩된 파일 시스템 이미지를 이용해 `fsimage`파일을 갱신
- `editslog`를 초기화
- 데이터노드가 전송한 블록리포트를 메모리에 로딩된 파일 시스템 이미지에 적용

#### 보조네임노드
- 네임노드는 메타데이터를 메모리에서 처리한다. 하지만 메모리에만 데이터를 유지할 경우 서버가 재부팅될 경우 모든 메타데이터가 유실될수 있다.
- HDFS는 `editslog`와 `fsimage`의 파일로 문제점을 극복한다.
- `editslog`는 HDFS의 모든 변경 이력을 저장한다. HDFS는 클라이언트가 파일을 저장하거나 삭제등을 할경우 `editslog`와 메모리에 로딩되어 있는 메타데이터에 기록한다.
- `fsimage`는 메모리에 저장된 메타데이터의 파일 시스템 이미지를 저장한 파일이다.
- 상위의 단계는 평상시에는 아무런 문제가 없지만 `editslog`의 크기가 클 경우 문제가 될수 있다.
- 이러한 문제를 해결하기 위하여 HDFS는 보조네임노드라는 노드를 제공한다.
- 보조네임노드는 주기적으로 네임노드의 `fsimage`를 갱신하는 역할을 하며, 이러한 작업을 체크포인트라고 한다.

#### 보조네임노드 - 체크포인팅
- 보조네임노드는 네임노드에게 `editslog`를 롤링할 것을 요청한다.(로그 롤링은 현재 로그 파일의 이름을 변경하고, 원래 이름으로 새 로그 파일을 만드는것이다.)
- 네임노드는 기존 `editslog`를 롤링한 후, `editslog.new`를 생성
- 보조네임노드는 네임노드에 저장된 롤링된 `editslog`와 `fsimage`를 다운한다.
- 보조네임노드는 다운받은 `fsimage`를 메모리를 로딩하고, `editslog`에 있는 변경 이력을 메모리에 로딩된 파일 시스템 이미지에 적용한다. 메모리 갱신이 완료되면 새로운 `fsimage`를 생성하며, 이 파일을 체크포인팅할 때 사용한다. `fsimage.ckpt`로 생성된다.
- 보조네임노드 `fsimage.ckpt`를 네임노드에게 전송
- 네임노드는 로컬에 저장되어 있던 `fsimage`를 보조네임노드가 전송한 `fsimage.ckpt`로 변경한다. 그리고 `editslog.new`파일명을 `editslog`로 변경
- 체크포인팅이 완료되면 네임노드의 `fsimage`는 최신 내역으로 갱신되고 `editslog`의 크기도 축소된다. 체크포인팅은 1시간마다 한 번씩 일어난다.
- 보조네임노드는 네임노드의 `fsimage`를 축소시켜주는 역할을 담당할뿐, 백업 서버가 아니다.
- 사전에 방지하도록 주기적으로 보조네임노드가 제대로 구동되고 있는지, `editslog`의 용량이 과도하게 증가하지 않았는지 확인해야한다.

### 클러스터 웹 인터페이스
- HDFS의 기본적인 상태를 모니터링하고 HDFS내에 저장된 파일을 조화할 수 있게 웹 인터페이스를 제공
- `http://namenode:50070`
- 이 주소는 `hadoop-site.xml`의 `dfs.http.address`속성을 수정해서 변경할수 있다.