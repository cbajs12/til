##  Spark Streaming
- 사용자들이 배치 작업에 썻던 것과 유사한 API를 통해 스트리밍 애플리케이션을 작성할 수 있도록 해주며 기존에 썼던 기술과 코드를 재활용할 수 있도록 도와준다.
- 배치 프로그램과 달리 스파크 스트리밍은 무중단 동작을 위해서는 추가적인 셋업이 필요하다.
- StreamingContext를 생성하는 것으로 시작한다. 이 작업은 하부 계층에 존재할 SparkContext도 생성하게 되며 이는 데이터를 처리하는 데에 사용된다.

### DStrem
- DStream(시간별로 도착한 데이터들의 연속적인 모음)이라는 추상화 개념을 바탕으로 한다.
- 내부적으로 각각의 DStream은 각 시간별로 도착한 RDD들의 연속적인 모음으로 구성된다.
- DStream은 새로운 DStream을 만들어 낼 수 있는 트랜스 포메이션 연산과 외부 시스템에 데이터를 써주는 결과 연산을 가지고 있다.
- DStream은 RDD에서 가능한 것과 동일한 종류의 많은 연산들을 지원하며, 시간 관련이나 슬라이딩 윈도같은 특별한 기능도 지원한다.

### 아키텍처와 추상 개념
- 스파크 스트리밍은 마이크로 배치라 불리우는 아키텍처를 사용한다.
- 스트리밍 처리를 데이터의 작은 배치 단위들 위에서 각 배치 처리의 연속적인 흐름으로 간주한다.
- 새로운 배치들은 정해진 시간 간격마다 만들어지게 된다. 매시간 간격의 시작 단계에 새로운 배치가 만들어지며, 시간 간격 동안 받아들인 데이터가 배치에 계속 추가 된다.
- 각 입력 배치는 RDD의 형태이며 스파크 작업을 사용하여 다른 RDD를 생성하도록 처리된다.
- 출력 연산은 데이터를 외부 시스템에 쓴다는 점에서 RDD 액션과 유사하나 스트리밍에서 이는 매시간 단계마다 주기적으로 실행되며 출력을 묶음(배치) 단위로 생성한다.
- 스파크 내부에서 스트리밍 실행은 이렇다. 각 입력 소스마다 스파크 스트리밍은 리시버를 실행시키는데, 이는 애플리케이션의 익스큐터들 안에서 데이터를 모으고 RDD에 저장하는 테스크이다. 이들은 데이터를 받아 장애 대응을 위해 다른 익스큐터에 복제한다. 이 데이터는 캐시되는 RDD와 동일한 방식으로 익스큐터 메모리에 저장된다. `StreamingContext`는 이 데이터들을 처리하기 위해 주기적으로 스파크 작업들을 실행하고 이전 시간 단계의 RDD와 연결한다.
- 스파크 스트리밍은 스파크가 RDD를 위해 제공하는 것과 동일한 장애 대응 속성들을 제공한다. 입력 데이터의 복제본이 사용 가능한 한, RDD들의 가계도를 이용하여 어떤 상태에서라도 결과를 재연산할 수 있다. 받은 데이터는 기본적으로 두개의 노드에 복제되므로 스파크 스트리밍은 단일 작업 노드 장애에 대응할 수 있다.
- 그러나 단순히 가계도를 이용하면 재연산이 프로그램 시작단계에서부터 다시 이루어지므로 체크포인팅이라는 견고한 파일 시스템(HDFS등)에 주기적으로 상태를 저장하는 메커니즘을 따로 가지고 있다.

### 트랜스포메이션
- 무상태 : 각 배치의 처리가 앞쪽의 배치들에 있는 데이터와 상관없이 진행된다. 일반적인 RDD 트랜스포메이션들이 포함
- 상태 유지 : 현재 배치의 결과를 만들기 위해 이전 배치의 데이터나 중간 결과를 이용한다. 슬라이싱 윈도, 시간별 상태 추적등이 존재

#### 무상태 트랜스포메이션
- DStream내의 모든 RDD에 적용된다.
- 그러나 내부적으로 각 DStream은 여러 개의 RDD로 구성되며 각각의 무상태 트랜스포메이션은 각 RDD에 구분되어 적용된다.

#### 상태 유지 트랜스포메이션
- 시간 단계 범위를 넘어서 데이터를 추적하는 DStream연산이다. 이전 배치들의 데이터가 새로운 배치의 결과를 생성하기 위해 쓰인다.
- 상태 유지 트랜스포메이션은 장애 대응을 위해 StreamingContext에서 체크포인팅 활성화를 필요로 한다.

##### 위도 트랜포메이션
- 윈도 트랜스포메이션은 여러 배치들의 결과를 합쳐서 StreamingContext의 배치 간격보다 훨씬 긴 시간 간격에 대한 결과를 계산한다.
- 모든 윈도 연산들은 윈도 시간과, 슬라이딩 시간을 필요로 하며, 두 값 모두 StreamingContext의 배치 간격의 배수여야 한다.
- 윈도 시간은 자나간 배치를 몇개나 사용할지를 제어하며 개수만큼 최근 배치들을 쓰게 된다.
- 슬라이딩 시간은 기본값이 배치 간격과 동일하며 얼마나 자주 새로운 DStream이 결과를 계산할지를 결정한다.

##### updateStateByKey 트랜스포메이션
- DStream안에서 배치들을 통틀어 유지되는 상태가 존재하게 할때 사용한다.
- 키, 이벤트쌍의 DStream이 주어지면, 새 이벤트에 주어진 각 키를 업데이트하도록 정의된 함수를 받아들여 새로운 쌍의 DStream을 만들수 있게 한다.
- 이 함수를 쓰려면 도착한 이벤트와 이전 상태를 받아들이는 update() 함수를 작성하여 업데이트된 결과를 저장한 newState를 되돌려준다.
- 이 함수의 결과는 매시간 단계마다의 키, 상태쌍들의 RDD를 가지는 새로운 DStream이 된다.

### 출력 연산
- 스트림에서 최종 트랜스포메이션의 결과에서 무엇이 필요한가를 정의하는 것이다.
- 주의할 점은 출력 연산이 없다면 연산이 되지 않는다. 특히, StreamingContext에 출력 연산이 지정되지 않았다면 시작되지도 않는다.

### 입력 소스
- 스파크 스트리밍은 다수의 입력 소스에 대한 지원을 내장하고 있다. 일부는 추가적인 아티펙트를 써야만 가능하다.

#### 핵심 소스
- 핵심 소스들로부터 DStream을 생성하는 메소드들은 모두 StreamingContext에서 사용할 수 있다.
- 스파크는 모든 하둡 호환 파일 시스템에서 읽기를 지원하므로 스트리밍은 자연히 하둡 호환 파일 시스템의 디렉터리에 쓰여진 파일로부터 스트림을 만드는 것을 자연스럽게 지원한다.
- 스트리밍 소스로 아카 액터를 쓸수 있게 해주는 acotrStream도 존재한다.

#### 그외 소스
- 아파치 카프카, 아파치 플럼, 사용자 입력 소스들이 존재한다.

#### 여러 입력소스 사용과 클러스터 사이징
- 여러 개의 DStream을 연결하는 것이 가능하다.
- 가끔 여러 개의 리시버를 쓰는 것은 데이터 수집시 집합 연산의 처리량을 늘리기 위해서 필요하다.
- 각 리시버는 스파크의 익스큐터 내에서 지속적으로 실행 중인 태스크가 되어 돌아간다. 리시버는 애플리케이션에 할당된 CPU 코어를 차지하게 된다. 여러개의 리시버를 운영하기 위해 최소 리시버 개수만큼의 코어가 필요하며, 추가로 연산을 위한 코어가 더 필요하다.

### 상시 운영
- 입력 데이터가 안정적으로 저장되어 있는 한 스파크 스트리밍은 언제나 올바른 결과를 계산해 낼수 있으며, 심지어 드라이버나 작업노드에 장애가 생겨도 사용자가 재실행할 필요없이 처리된다.
- 이를 위해서는 특수 설정이 필요한데 체크 포인팅을 설정하는 것이다.

#### 체크 포인팅
- 스파크 스트리밍이 복구를 위해 HDFS나 S3 같은 안정적인 파일 시스템에 주기적으로 애플리케이션의 데이터를 저장하게 해 준다.
- 체크 포인팅은 장애 시 재연산이 필요한 상황을 제한하고, 드라이버에 대해 장애 대응 가능을 제공한다.

#### 드라이버 장애 대응
- 드라이버 노드의 장애에 대응하는 것은 StreamingContext의 생성 시 체크포인트 디렉터리를 받아 들이도록 하기위하여 `StreamingContext.getOrCreate()` 함수를 써야 한다.
- 이 방법 이외에도 monit같은 도구로 프로그램을 감시하고 재시작 해주는 방법이 있다.

#### 작업 노드 장애 내구성
- 작업 노드의 장애에 대해 스트리밍은 스파크와 같은 방식으로 동작한다.

#### 리시버 장애 내구성
- 스트리밍은 클러스터의 다른 노드에서 실패한 리시버를 재시작한다. 데이터가 유실될 가능성은 입력 소스의 동작 방식과 리시버의 구현에 따라 다르다.
- 모든 데이터가 처리되었다는 것을 확신하기 위한 가장 좋은 방법은 안정적인 입력 소스를 쓰는 것이다.
- 안정적이지 않은 입력 소스(푸시 기반 모델)를 사용한다면 스파크 1.2와 WAL(실제 사용전에 로깅부터 하여 장애시 로그 기반 복구를 시도)을 활성화 한다.

#### 작업 처리 보장
- 스파크 스트리밍의 작업 노드 장애 내구성에 대한 보장 덕택에 모든 트랜스포메이션 대해 `딱 한번 처리`의 콘셉트 제공이 가능하다.
- 노드의 장애로 일부 데이터가 재처리 될지언정, 최종 결과는 정상적으로 처리된다.
- 출력 연산으로 외부에 결과를 보낼때 결과를 푸시하는 태스크들은 오류로 여러 번 실행되고 일부 데이터가 여러번 보내질수도 있다. 이것은 외부와 연계 문제이다. 해결로 푸쉬할 때 트랜잭션(한번에 RDD파티션 하나씩 원자적으로 보냄)을 사용할 수 있고 업데이트가 멱등 연산(여러번 적용해도 동일한 결과가 나오는 연산)이 되도록 설계할 수도 있다.

### 성능 고려 사항
#### 배치/윈도 크기
- 대개는 500밀리초의 배치 크기가 최적의 최소 크기이다.
- 찾는 좋은 방법은 큰 배치부터 줄여가며 처리 시간이 일정하면 계속 줄이고, 처리 시간이 길면 애플리케이션 한계에 도달한 것이다.

#### 병렬화 수준
- 리시버 개수 늘리기 : 여러 개의 입력 DStream을 만들어 리시버르 추가하고, union을 적용해 합쳐 단일 스트림으로 보내주면 된다.
- 받은 데이터를 명시적으로 재파티셔닝 : 리시버를 늘리기 힘들면 입력 스트림을 재파티셔닝해 받은 데이터를 재배치할 수 있다.
- 집합 연산 시 병렬화 개수 늘기기

#### 가바지 컬렉션과 메모리 사용량
- 자바의 병렬 마크 스윕 가비지 컬렉터를 써서 예측되지 않은 GC에 의한 일시 정지를 최소화 할 수 있다.
- 직렬화 형태로 RDD를 캐싱하는것은 GC의 부담을 줄여준다.(kyro직렬화등)
- `spark.cleaner.ttl`을 설정하면 스파크는 특정 시간이 지난 RDD들을 캐시에서 삭제할수 있다. 이것으로도 GC의 부담을 줄일수 있다.