## Basic & RDD

### Basic
- 연산 과정을 클러스터 전체에 걸쳐 자동으로 병렬화해 분산 배치된 연산 작업들의 모음을 `RDD`라 한다. (단순하게는 분산되어 존재하는 데이터 요소들의 모임이다.)
- 클러스터에서 다양한 병렬 연산을 수행하는 드러이버 프로그램으로 구성
- 드라이버 프로그램들은 연산 클러스터에 대한 연결을 나타내는 `SparkContext`객체를 통해 스파크에 접속 한다.
- `SparkContext`객체를 하나 만들었다면, 그것으로 RDD를 만들수 있다.
- 다양한 연산을 수행하기 위해 드라이버 프로그램들은 익스큐터라 불리는 다수의 `노드(클러스터의 머신 하나)`를 관리한다.
- 스파크는 사용자가 제작한 코드를 여러개의 노드에서 돌아갈수 있도록 지원해준다.

###  RDD

#### 기초
- 분산되어 잇는 변경 불가능한 객체 모음
- 각 RDD는 클러스터의 서로 다른 노드들에서 연산 가능하도록 여러 개의 파티션으로 나뉜다.
- RDD는 외부 데이터셋을 로드하거나 드라이버 프로그램에서 객체 컬렉션(list, set등)을 분산시키는 방법으로 만들수 있다.
- `transformation` - 조건을 주어 새로운 RDD를 만드렁 내는것
- `action` - RDD를 기초로 결과 값을 계산하며 그 값을 드라이버 프로그램에 되돌려 주거나 외부 스토리지에 저장하기도 한다.
- 스파크는 RDD처리시에 여유로운방식(lazy evaluation)으로 처음 액션을 사용하는 시점에 처리한다. 즉, 처리할정도의 데이터만 불러와 처리한다. (액션을 하기위해 모든 데이터를 한번에 불러오지 않는다.)
- RDD들은 기본적으로 액션이 실행될때마다 매번 새로 연산을 한다. 
- 만약 RDD하나를 재사용하고 싶으면 `RDD.persist()`를 사용하여 계속 결과를 유지하도록 요청할수있다.
- `parallelize()`를 사용하면 프로그램에 있는 데이터 셋을 가져다가 사용할수있다. 그러나 이방식은 하나의 머신 메모리에 모든 데이터 셋을 담아서 프로토타이핑 혹은 테스팅 목적이 아니면 잘 사용되지 않는다.
- `textFile()`은 외부 스토리지에서 데이터를 불러오는것이다.
```python
conf = SparkConf().setMaster("local").setAppName("myApp")
sc = SparkContext(conf=conf)

lines = sc.parallelize(["pandas", "cute"])
lines = sc.textFile("/path/to/file")
```

#### RDD 연산
- 트랜스포메이션은 RDD를 반환하고, 액션은 데이터 타입을 반환한다.

##### 트랜스포메이션
- 트랜스포메이션된 RDD는 실제로 액션을 실행되는 시점에 계산된다.
- 많은 트랜스포메이션들은 데이터요소 위주, 즉 한번에 하나의 요소에서만 작업이 이루어진다.
- `fileter()`연산은 이미 존재하는 RDD를 변경하지 않는다. 대신 새로운 RDD에 대한 포인터를 리턴한다. (대부분의 트랜스포메이션들이 이렇게 작용한다.)
- 트랜스포메이션들은 입력할 수 있는 RDD개숭에 대한 제한이 없다.

##### 액션
- 실제로 결과 값을 내어야 하므로 트랜스포메이션이 계산을 수행하도록 강제한다.
- `take()` - RDD의 데이터 일부를 가져오기 위한 함수
- `collect()`- 전체 RDD 데이터를 가져올수 있게 해준다. 전체 데이터셋이 단일 컴퓨터 메모리에 올라올수 있을 정도의 크기여야한다. (이를 처리 위해서는 HDFS나 S3같은 분산 파일 시스템을 사용)
- 새로운 액션을 호출할 때마다 전체 RDD가 처음부터 계산을 새로이 한다.

##### lazy evaluation
- RDD에 대한 트랜스포메이션을 호출할때 메타데이터에 연산이 요청되었음을 기록한다.
- 필요한 시점이 되기 전까지는 실행되지 않는다.
- 스파크는 연산들을 그룹지어서 데이터를 전달해야 하는 횟수를 줄이기 위해 이 방식을 사용한다.

##### caching
- 동일한 RDD를 여러번 사용하고 싶을때 사용
- RDD 영속화(persist)에 대한 요청을 하면 RDD를 계산한 노드들은 그 파티션들을 저장하고 있게된다.
- 영속화된 데이터를 갖고 있느 노드에 장애가 생기면 필요시 유실된 데이터 파티션을 재연산한다.
- `persist()` - (자바와 스칼라)데이터를 JVM 힘에 직렬화되지 않은 객체 형태로 저장한다. (파이썬) JVM힙에 피클(파이썬의 직렬화)된 객체가 저장된다.
- 데이터를 디스크나 오프힙 저장공간에 쓸때는 데이터가 늘 직렬화한다.
- `persist()`호출은 연산을 강제로 수행하지는 않는다.
- 만약 메모리에 많은 데이터를 올리려고 시도하면 스파크는 LRU(최근 사용된 것들은 남기고 오래된 것을 버린다)정책에 따라 오래된 파티션들을 버린다.
- 디스크와 메모리를 같이 쓴다면, 오래된 것들은 디스크로 옮겨진다.
- `unpersist()` - 직접 캐시에서 데이터를 삭제
