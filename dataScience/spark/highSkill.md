## Spark high skill

### 공유 변수
- 클러스터에서 실행 중인 각각의 작업들은 변수의 복사본을 받아 작업하게 되므로 업데이트된 내용이 다시 드라이버 프로그램으로 돌아오지 않는다.
- 일반적인 통신 타입인 결과의 집합연산과 브로드캐스팅에 대해 이러한 제한을 풀어 준다.

#### 어큐뮬레이터
- 작업 노드에서 드라이버 프로그램으로 보내는 값의 집합 연산에 대해 간단한 문법을 제공
- 작업 수행 중에 발생하는 일에 대한 개수를 디버깅 목적으로 헤아린다.
- 드라이버에서 SparkContext.accumulator(initialValue)메소드를 호출하여 초기 값을 가진 어큐뮬레이터를 만든다. 반환 타입은 org.apache.spark.Accumulator[T] 객체이며 T는 초기값의 타입이다.
- 스파크 클로저의 작업 노드 코드에서 어큐뮬레이터에 +=메소드를 써서 값을 더한다.
- 드라이버 프로그램에서 value속성을 불러 어큐뮬레이터의 값에 접근한다.
- 작업 노드의 태스크 관점에서 어큐뮬레이터는 쓰기전용 변수이다. 어큐뮬레이터가 매 업데이트마다 통신할 필요가 없도록 효율적으로 구현되어 있기 때문
- 오류가 발생한 작업들에 대해 재실행 하는 방식으로 대응한다. 어큐뮬레이터의 최종 결과는 액션에 사용되었던 어큐뮬레이터들에 대한 것이며, 각 태스크의 업데이트는 스파크에 의해 각 어큐뮬레이터에 한 번씩만 방영된다. 즉, 장애나 반복 연산의 횟수와 관계없이 절대적으로 믿을 만한 값을 얻기를 원한다면 foreach()같은 액션안에 넣어야 한다.
- 액션이 아닌 RDD 트랜스포메이션에 사용되는 어큐뮬레이터에 대해서는 이러한 보장을 할수 없다.
- 트랜스포메이션 안에서 어큐뮬레이트는 되도록 디버깅 목적으로만 쓰여야 한다.

#### 브로드캐스트
- 스파크 연산에 쓸 크고 읽기 전용인 값을 모든 작업 노드에 효과적으로 전송하는데에 쓴다.
- T 타입의 객체에 spark.boradcast.Broadcast[T]를 호출하여 Broadcast[T ]를 만든다. Serializable이라면 어떤 객체든 가능하다.
- value 속성으로 값에 접근한다.
- 변수는 각 노드에 한번만 보내지며 읽기 전용으로 취급된다.(변경하더라도 다르 노느에 전파되지않는다.)
- 브로드캐스트 최적화를 하려면 빠르고 작은 크기의 데이터 직렬화 포맷을 선택하는 것이 중요하다.

### 파티션별 작업
- 각 데이터 아이템에 대해 셋업 절차의 반복을 피하게 해준다.
- 파티션 기반 버전의 map과 foreach를 제공하여 RDD의 각 파티션들에서 한 번만 코드를 실행하게 해 줌으로써 그런 작업들에 대한 비용을 줄여준다.
- 파티션별 작업을 할 경우에 스파크는 사용자가 만든 함수에 그 파티션의 데이터가 담긴 Iterator를 준다.

### pipe() 메소드
- 다른 언어에서 스파크로 데이터를 연결해 주는 파이프 메커니즘을 제공한다.
- pipe() 메소드를 통해 유닉스 표준 입출력 스트림으로 읽고 쓸 수 있는 모든 언어로 작업의 일부를 작성할 수 있다.
- 각 RDD의 데이터를 표준 입력으로부터 String으로 읽어들이는 트랜스포메이션을 만드수 있고, 이 문자열을 원하는 대로 가공하여 표준 출력으로부터 결과를 String으로 써줄수 있다.

### 수치 데이터
- 한 번에 하나씩 처리하는 방식으로 수치 모델을 처리하도록 하는 스트리밍 방식 알고리즘으로 구현되어 있다.
