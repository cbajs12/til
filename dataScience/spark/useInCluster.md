## Using in cluster
### 스파크 구조
- 마스터/슬레이브 구조 (드라이버/익스큐터)
- 드라이버와 익스큐터는 각각의 자바 프로세스에서 동작한다.
- 하나의 드라이버와 익큐터들을 합쳐 스파크 어플리케이션이라 하고, 이 어플리케이션은 클러스터 매니저라고 불리는 외부 서비스를 써서 여러 개의 머신에서 실행된다.

### 드라이버
- 프로그램의 main() 메소드가 실행되는 프로세스
- SparkContext를 생성하고 RDD를 만들고 트랜스포메이션과 액션을 실행하는 사용자 코드를 실행하는 프로세스
- 드라이버가 종료되면 어플리케이션도 종료된다.

#### 사용자 프로그램을 태스크로 변환
- 드라이버는 사용자 프로그램을 물리적 실행 단위가 되는 태스크로 바꿀 책임을 가진다.
- 상위수준에서 모든 스파크 프로그램은 동일한 구조를 갖는다. 입력으로부터 RDD를 만들고, 트랜스포메이션을 사용하여 새로운 RDD를 받아오며, 데이터를 가져오거나 저장하기 위해 액션을 사용한다.
- 내부적으로는 연산들의 관계에 대해 논리적인 지향성 비순환 그래프(DAG)를 생성한다. 드라이버가 실행될때, 드라이버는 이 논리 그래프를 물리적인 실행 계획으로 변환한다.
- 스파크는 맵 트랜스포메이션을 파이프라이닝해서 합치는 등의 여러가지 최적화를 통해 실행 그래프를 여러 개의 단계로 바꾼다. 각 단계는 순서에 따라 여러 개의 태스크로 이루어지며 단위 작업들은 묶여서 클러스터로 전송된다.
- 태스크는 스파크의 작업 계층에서 가장 작은 단위의 개체이다.

#### 익스큐터에서 태스크의 스케쥴링
- 물리적 실행 계획이 주어지면 스파크 드라이버는 익스큐터들에서의 개별 작업들을 위한 스케줄을 조정한다.
- 익스큐터들은 시작하면서 드라이버에 등록을 하게 되므로 드라이버는 항상 어플리케이션의 실행에 대해 전체적으로 볼수있다.
- 드라이버는 항상 실행중인 익스큐터들을 살펴보고 각 태스크를 데이터 위치에 기반해 적절한 위치에서 실행될수 있도록 노력한다.
- 작업들이 실행되면 이미 캐시된 데이터를 또 저장하는 부작용이 있을수 있다. 드라이버는 이것들을 추적하여 그 데이터를 사용하게 될 이후의 작업들이 적절하게 스케줄될수 있도록 한다.
- 드라이버는 4040포트를 사용하는 웹 인터페이스를 통해 실행정보를 보여준다.

### 익스큐터
- 주어진 스파크 작업의 개별 태스크들을 실행하는 작업 실행 프로세스이다.
- 익스큐터는 스파크 어플리케이션 실행 시 최초 한번 실행되며, 대개 어플리케이션이 끝날때 까지 계속 동작하지만 익스큐터가 죽더라도 스파크 어플리케이션은 계속 실행된다.
- 어플리케이션을 구성하는 작업들을 실행하여 드라이버에 그 결과를 되돌려준다.
- 각 익스큐터 안에 존재하는 블록 매니저라는 서비스를 통해 사용자 프로그램에서 캐시하는 RDD를 저장하기 위한 메모리 저장소를 제공한다. RDD가 익스큐터 내부에 직접 캐시되므로 단위 작업들 또한 같이 실행되기 용이하다.
- 로컬 모드에서는 스파크 드라이버가 익스큐터와 동일한 자바 프로세스 안에서 실행된다.

### 클러스터 매니저
- 스파크는 익스큐터를 실행하거나 때때로 드라이버를 실행을 위해서라도 클러스터 매니저에 의존한다.
- 스파크와 붙이거나 뗄 수있는(pluggable) 컴포넌트이다.
- 스파크가 얀, 메소스, 내장 매니저등의 외부 매니저들 위에서도 돌아갈 수 있게 한다.
- 스파크는 드라이버와 익스큐터 모두를 얀 작업 노드들 위에서 실행할 수 있다.

### 프로그램 실행
- 스파크는 사용자 프로그램을 스파크에 제출할 수 있는 단일 스크립트인 spark-submit을 제공한다.
- spark-submit은 다른 클러스터 매너저들에 접속할 수 있으며 사용자의 어플리케이션이 얼마나 많은 자원을 쓸지 조정할 수 있다.

#### 단계
- 사용자는 spark-submit을 사용하여 어플리케이션을 제출한다.
- spark-submit은 드라이버 프로그램을 실행하고 사용자가 정의한 main() 메소드를 호출한다.
- 드라이버 프로그램은 클러스터 매니저에게 익스큐터 실행을 위한 리소스를 요청한다.
- 클러스터 매너저는 드라이버 프로그램을 대신해 익스큐터들을 실행한다.
- 드라이버 프로세스가 사용자 어플리케이션을 통해 실행된다. 프로그램에 작성된 RDD의 트랜스포메이션과 액션에 기반하여 드라이버는 작업 내역을 단위 작업 형태로 나눠 익스큐터들에게 보낸다.
- 단위 작업들은 결과를 계산하고 저장하기 위해 익스큐터에 의해 실행된다.
- 드라이버의 main()이 끝나거나 SparkContext.stop()이 호출된다면 익스큐터들은 중지되고 클러스터 매니저에 사용했던 자원을 반환한다.

### 의존성 라이브러리 패키징
- 어플리케이션을 묶을때 의존성 리스트에 스파크를 포함시킬 필요는 없다. spark-submit은 자동적으로 사용자 프로그램의 경로에 스파크가 존재하도록 처리해 준다.
- 스파크에 어플리케이션을 제출할 때는 전체적인 전이 의존성 그래프를 같이 전송해야 한다. 이것은 직접, 간접, 간접의 간접 라이브러리등도 모두 포함한다.

### 스파크 어플리케이션 간의 스케쥴링
- 스케줄링 정책은 자원이 고갈되지 않고 작업 부하의 우선순위에 따라 할당되도록 도와준다.
- 다중 접속 환경 클러스터에서의 스파크는 기본적으로 클러스터 매니저가 스파크 어플리케이션들 사이에서 자원을 공유/관리해 주는 기능에 의존하여 스케줄링한다.
- 클러스터 매니저로부터 익스큐터를 요청하면 가능한 상태나 자원 경쟁 여부에 따라 적당한 개수의 익스큐터가 주어진다.
- 스파크 어플리케이션중 특별한 경우는 장시간 동작하며 기본적으로 끝나지 않도록 만들어진 경우이다.
- 스파크가 내부적으로 제공하는 페어 스케줄러는 장시간 동작 어플리케이션이 작업 스케줄링을 위해 우선순위 조정을 할 수 있도록 큐를 제공한다.

### 여러 클러스터 매니저
#### 단독 클러스터 매니저
- 단독 클러스터에 어플리케이션을 하나의 마스터와 여러 개의 작업자로 구성되며, 각각은 설정에 따른 용량의 메모리와 CPU 코어만큼을 사용한다.
- 단독 클러스터 매니저는 직접 마스터와 작업자를 실행하거나 스파크의 sbin 디렉터리의 실행 스크립트를 써서 시작할수 있다.

#### 하둡 얀
- 다양한 데이터 처리 프레임워크들이 공유된 자원 풀을 쓸 수 있도록 하기 위한 것
- 스파크를 얀 위에서 실행한다면 원하는 데이터가 저장된 HDFS 위에서 스파크가 돌아가게 되므로 유용하다.
- 클라이언트 모드는 어플리케이션을 제출한 머신에서 어플리케이션을 위한 드라이버 프로그램이 실행된다.
- 클러스터 모드는 드라이버가 얀 컨테이너 내부에서 실행된다.

#### 아파치 메소스
- 클러스터에서 분석 워크로드나 장시간 동작 서비스 모두 사용할수 있게 해주는 범용 목적의 클러스터 매니저이다.
- 주키퍼를 써서 멀티 마스터 모드에서 주키퍼가 마스터를 고르도록 메소스 클러스터를 설정할 수도 있다.
- 세밀한 모드는 기본모드이며 실행하는 단위 작업들에 따라 익스큐터가 메소스에 요청하는 CPU개수를 조정하므로 여러 개의 익스큐터를 한 머신에서 실행하더라도 익스큐터들 사이에 동적으로 자원을 공유할 수 있다.
- 거친 모드는 각 익스큐터에 고정된 개수의 CPU를 할당하고 어플리케이션이 종료하기 전까지, 심지어 익스큐터가 아무 일도 하지 않아도 결코 반환하지 않는다.
- 세밀한 메소스 모드는 다중 사용자 모드에서 셀 같은 대화형 작업들이 클러스터를 공유할 때 매력적이다, 아무것도 하지 않을 경우 어플리케이션은 알아서 사용하는 코어 수를 줄이게 되고 그 상태에서도 다른 사용자 프로그램들은 여전히 클러스터를 쓸수 있기 때문이다. 단점은 세밀한 모드에서 스케줄링되는 작업들은 응답성이 나빠지며, 사용자가 새로운 명령을 입력할 경우 다시 적정한 숫자의 CPU 코어가 사용 가능해질 때까지 기다려야 될수도 있다.

#### 아마존 EC2
- 스파크에는 아마존 EC2에서 클러스터를 실행할 수 있는 내장 스크립트가 들어 있다.

#### 클러스터 매니저 적용
- 새로 배포할 예정의 어플리케이션이라면 단독 클러스터로 시작한다, 셋업이 가장 쉽고 스파크만 돌릴 경우 다른 클러스터 매니저들이 제공하는 거의 모든 기능을 동일하게 제공한다.
- 스파크를 다른 어플리케이션들과 같이 돌리고 싶거나 우수한 자원 스케줄링 기능을 써야한다면, 얀과 메소스를 사용한다.
- 메소스의 장점은 스파크 셀 같은 대화형 어플리케이션들의 명령 실행 간에 CPU 사용량을 자동으로 낮추는 세밀한 공유 옵션이다.
- 스파크는 저장소에 빠른 접근을 위해 HDFS와 동일한 노드에 설치되는 것이 최상이다.