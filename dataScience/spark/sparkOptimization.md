## spark optimization
- SparkConf객체는 사용자가 재정의해서 쓸 수 있는 설정 옵션들에 대한 키와 값의 쌍들을 갖고 있다.
- 직접 만든 SparkConf 객체를 사용하려면 set()을 호출하여 설정값들을 추가하고, 이를 SparkContext 생성자에 넣어주면 된다.
- `setAppName`, `setMaster()`를 호출하여, spark.app.name과 spark.master 설정값을 각각 정의할 수 있다.
- 스파크는 spark-submit 도구를 써서 동적으로 설정값을 지정할 수 있다.
- spark-submit은 설정값을 파일에서 읽는 것도 지원한다. spark-submit은 스파크 디렉터리의 conf/spark-defaults.conf를 찾은뒤 파일에서 공백으로 구분된 키와 값 쌍을 찾는다.
- 동일한 설정 속성값이 여러 곳에 지정되는 경우, 스파크는 정해진 우선순위를 따른다 (SparkConf에 직접 -> spark-submit -> 설정 파일 -> 기본값)
- 데이터를 셔플하는 데이 쓸 로컬 저장 디렉터리를 지정하기위한 `SPARK_LOCAL_DIRS`는 따로 설정해야 한다.

### 작업, 태스크, 작업 단계
- RDD에서 트랜스포메이션이 실행되면 프로그램은 어떤 액션도 수행하지 않지만, 내부적으로 정의된 RDD객체들의 지향성 비순환 그래프(DAG)를 갖게되고, 나중에 액션을 수행시에 사용한다.
- 각 RDD는 자신이 어떤 타입의 관계를 갖고 있는지에 대한 메타데이터에 따라 하나 이상의 부모 RDD를 가르키는 포인터를 유지한다.
- 스파크의 스케쥴러는 액션을 수행할 때 필요한 RDD 연산의 물리적 실행 계획을 만든다.
- 액션을 수행시,  RDD의 모든 파티션이 실체화되고 드라이버 프로그램으로 전송된다.
- 스케줄러는 연산되는 마지막 RDD에서 시작하여 연산해야 할 것을 역으로 추적해 나간다. 그러므로써 모든 조상 RDD들을 연산하기 위해 필요한 물리적 실행계획을 재귀적으로 만들어 낸다.
- 스케줄러가 파이프라이닝을 수행하거나, 여러 개의 RDD를 하나의 작업 단계로 합치는 경우에 물리적인 작업 단계들이 연관된 RDD그래프와 1:1매치되지 않는 경우가 발생한다.
- 파이프라이닝은 RDD들이 데이터 이동 없이 부모에서부터 연산이 가능할 때 발생한다.
- 스파크의 내부 스케줄러는 RDD가 이미 클러스터 메모리나 디스크에 캐싱되어 있는 경우 RDD그래프의 가계도를 제거할 수도 있다. 스파크는 이런 경우 건너뛰기를 시도하며 앞 부분은 생략하고 영속화되어 있는 RDD기준으로 연산을 시작한다.
- 가계도 제거가 일어나는 다른 경우는 이미 이전에 실행된 셔플링으로 인해, `persist()`가 호출되지 않았음에도 side effect로 RDD의 데이터가 남아 있는 경우이다.
- 특정 액션을 위해 생성되는 작업 단계들이 모여서 작업을 이룬다.
- 한 번 작업 단계 그래프가 정의되면 태스크들이 만들어지고 사용하는 배포 모드에 따라 다양하게 내부 스케줄러로 보내진다. 물리적 계획에서의 작업 단계들은 RDD 가계도에 따라 각자 의존성을 가지게 되므로 그에 맞는 순서로 실행된다.
- 물리적 작업 단계는 실행되는 데이터 파티션은 서로 다르지만 같은 일을 수행하는 태스크들을 실행시킨다. 각 태스크는 내부적으로 동일한 순서에 따라 수행된다.

> 1) 저장장치나 존재하는 RDD나 셔플의 결과물로부터 데이터를 가져온다.
> 2) RDD를 계산해 내기 위해 필요한 연산들을 수행한다.
> 3) 결과를 셔플이나 외부 저장장치에 쓰거나 드라이버에 되돌려 준다.

> 스파크의 실행
> 1) 사용자 코드가 RDD의 DAG를 정의한다.
> 2) DAG가 액션의 실행 계획으로 변환된다. -> 스파크의 스케줄러는 RDD들이 필요한 모든 연산을 수행하도록 작업을 제출한다. 이 작업은 하나 이상의 작업 단계를 갖게 되며, 이는 태스크들로 구성된 병렬 집단 연산들을 말한다. 각 작업 단계는 DAG에서 하나 이상의 RDD들과 연계된다. 하나의 작업단계가 파이프라이닝에 의해 여러개의 RDD와 연계될수 있다.
> 3) 태스크들이 스케줄링되고 클러스터에서 실행된다. -> 작업 단계들은 순서대로 실행되며 RDD의 조각들을 연산하기 위한 태스크들을 실행한다.

### 정보찾기
#### 스파크 웹 UI
- 4040포트로 접근가능 (드라이버 또는 쉘이 실행되고 있어야 한다.)
- Jobs는 실행중이거나 최근에 완료된 작업들에 대한 세부적인 진행상황과 작업 단계, 태스크들의 진행상황, 실행중인 작업에 대한 수치들을 제공한다.
- Stage 페이지는 모든 태스크들의 성능 수치 분포를 살펴봄으로써 성능 비대칭을 파악할 수 있게 도와준다.
- Storage는 영속화 되어 있는 RDD에 대한 정보를 보여준다.
- Executors는 활성화된 익스큐터들에 대해 작업 처리와 관련된 수치들과 각 익스큐터가 쓰고 있는 저장 장치의 용량을 보여준다.
- Environment는 스파크 어플리케이션의 실행 환경에서 활성화된 설정 속성들을 나열해 준다.

#### 드라이버와 익스큐터 로그
- 스파크 로그의 위치는 배포 모드에 따라 다르다
- 단독 모드에서 어플리케이션 로그는 마스터 웹  UI(8080)에 직접 표시된다. 기본적으로 각 작업 노드의 스파크 설치 위치의 work/ 아래에 저장된다.
- 스파크는 log4j를 사용한다.

### 성능 고려 사항
#### 병렬화 수준
- 스파크는 자체적으로 RDD의 병렬화 수준이 적당한지에 대해 추론해 동작하게 된다. 대개 입력 RDD는 하부의 저장 시스템에 기반하여 병렬화 수준을 선택한다.
- 병렬화 개수가 너무 적으면 스파크가 리소스들을 놀게하는 경우가 발생한다.
- 병렬화 개수가 너무 많다면 각 파티션에서의 작은 오버헤드라도 누적되면서 성능 문제가 심각해진다.
- 병렬화 수준을 조정할수 있는 두가지 방법이 있다. 데이터 셔플이 필요한 연산간에 생성된느 RDD를 위한 병렬 정도를 인자로 줄수 있다. 또는 이미 존재하는 RDD를 더 적거나 더 많은 파티션을 갖도록 재배치할 수있다.
- `repartition()`메소드는 RDD를 무작위로 섞어 원하는 개수의 파티션으로 다시 나눠준다.

#### 직렬화 포멧
- 스파크는 네트워크로 데이터를 전송하거나 디스크에 쓸 때 객체들을 직렬화해 바이너리 포맷으로 변환시켜야 한다. 이것은 셔플 작업동안 이루어진다.
- 스파크는 기본적으로 자바에 내장된 직렬화를 사용한다. 또는 서드파티 라이브러리인 `kyro`를 사용할수 도 있다.
- 사용자 코드에서 자바의 Serializable 인터페이스를 구현하지 않은 클래스를 참조한다면 에러를 만날수 있다.
- 클래스가 수정이 불가능한 상황이라면, 문제되는 클래스의 자식 클래스를 만들고 `Externalizalbe`인터페이스를 구현하거나, 카이로의 직렬화 동작을 수동설정 하는식으로 적용해야한다.

#### 메모리 관리
> 각 익스큐터 내부에서 메모리 사용 목적
> RDD 저장용 - RDD에 persist()나 cache()를 호출할 때 그 파티션들은 메모리 버퍼에 저장된다.
> 셔플 및 집한 연산 버퍼 - 셔플 연산 수행시 스파크는 셔플 출력 데이터를 저장하는 중간 버퍼를 만든다.
> 사용자 코드 - 스파크는 임의의 사용자 코드를 실행하게 되므로 사용자 코드 자체도 상당한 양의 메모리를 쓰게 될수 있다.

- 기본적으로 스파크는 RDD 저장용으로 60, 셔플 메모리에 20,  사용자 프로그램에 20을 배정한다. 경우에 따라서는 각 영역을 조정하므로써 메모리 고갈을 막을수 있다.
- 스파크의 기본 `cache()` 연산은 `MEMORY_ONLY`레벨로 메모리에 데이터를 저장하고 메모리가 모자라면 오래된 것들을 삭제한다. 이런 때 `persist()` 사용시 `MEMORY_AND_DISK` 레벨을 적용하면 삭제 대신 RDD 파티션을 디스크에 내리고 필요하면 메모리로 올린다.
- 또는, 기본 자바 객체를 캐시하지 않고 `MEMORY_ONLY_SER`나 `MEMORY_AND_DISK_SER`를 저장 옵션을 써서 직렬화된 객체를 저장하는 것이다. 직렬화 객체를 캐싱하는것은 직렬화 작업으로 조금 느리지만 가비지컬랙션에 걸리는 시간을 줄일수 있다.

### 하드웨어 프로비저닝
- 클러스터 사이징에 영향을 미치는 주요 인자들은 각 익스큐터에 지정되는 메모리양, 각 익스큐터에서 쓰는 코어 개수, 익스큐터의 총 개수, 각종 데이터에 사용되는 로컬 디스크 개수등이다.
- 스파크 어플리케이션은 많은 메모리와 코어가 있을수록 성능이 좋다. 스파크의 아키텍처는 선형 성능 증가를 이루도록 설계되었다.
- 익스큐터가 쓰는 메모리 사이징은 많을수록 좋지 않을수 있다. 너무 큰 힙을 지정하는 것은 가비지 컬렉션에 의한 정지 현상이 길어져 스파크 작업의 전체 처리량에 피해를 입힐수 있다.
