## Multi Regression
- 독립 변수와 오류 사이에 상관관계가 존재한다면, 최소자승법으로 만들어지는 모델은 편향된 beta를 추정해 준다.
- 부트스트랩은 기존의 데이터에서 중복이 허용된 재추출을 통해 새로운 데이터의 각 항목을 생성한다, 계수의 표준 오차를 추정할 떄도 적용할 수 있다.

### Regularization
- 변수가 많아질수록 모델이 학습 데이터에 오버피팅할 것이다.
- 0이 아닌 계수가 많을수록 모델을 해석하기 어려워 진다.
- Regularization은 beta가 커지면 커질수록 해당 모델에게 패널티를 주는 방법이다. 그리고 오류와 패널티를 동시에 최소화하는 최적의 모델을 만들 수 있다.
- ridge regression의 경우 bet_i를 제곱한 값의 합에 비례하는 패널티를 추가한다. 하지만 상수에 대한 패널티는 주지 않는다.
- lasso regression의 패널티는 모든 계수를 최대한 0으로 만들어 주며, 보다 희소한 모델을 학습하게 해준다.
