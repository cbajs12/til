## Machine Learning
### 모델링
- 모델은 다양한 변수 간의 수학적 관계를 표현한 것

### 기계학습
- 데이터를 통해 모델을 만들고 사용하는 것
- 지도학습 : 학습에 사용될 데이터에 정답이 포함 되어있는 것
- 비지도 학습: 학습에 사용될 데이터에 정답이 포함 되어 있지 않은 것
- 파라미터가 있는 parametric 모델을 고른후, 데이터를 통해 파라미터의 최적값을 찾으려고 한다.

### 오버피팅, 언더피팅
- 오버피팅 : 만들어진 모델의 성능이 학습 데이터에서는 좋지만, 기존에 관측한 적이 없는 새로운 데이터에선느 좋지 않은 경우(데이터의 잡음까지 모델에 학습되거나, 원하는 결과를 예측해주는 요소가 아닌 다른요소들이 학습되기 때문에 발생)
- 모델의 성능이 학습 데이터에서도 좋지 않은 경우 (해당 모델은 문제에 적합하지 않다는 것을 의미)
- 각각 다른 데이터로 모델을 학습시키고 평가하는 방법이 있다. 간단한 방법은 주어진 데이터를 나누는 것이다, 평가 데이터에 대한 성능이 좋은 모델은 오버피팅되지 않았다고 볼수 있다.
- 학습 데이터로 모델을 만들고, 검증 데이터를 통해 학습된 여러 모델 중 하나를 선택하고, 평가 데이터로 최종 모델의 성능을 평가할 수 있다.

### 정확도
- 모델을 선택하기 위해서는 정밀도와 재현율의 트레이드오프를 고려해야 한다. 특정 데이터 포인트가 조금이라도 양성일 것 같을때 모델이 데이터 포인트를 양성이라고 판단한다면, 재현율은 높겠지만 정밀도는 낮을 것이다. 반면 모델이 데이터가 확실히 양성일 때만 해당 데이터를 양성이라고 판단한다면 재현율은 낮겟지만 정밀도는 높을 것이다.

### Bias-variance 트레이드 오프
- 오버피팅 문제는 bias, variance의 트레이드오프로 볼 수있다.
- 만약 모델의 bias가 매우 심하다면, 새로운 변수를 추가하는 것도 하나의 해결책일 것이다.
- 만약 모델의 variance이 너무 높다면, 모델의 변수를 줄이거나 더 많은 데이터를 구해서 모델을 다시 학습시키면 된다.

### 특성 추출 및 선택
- 데이터의 특성이란 모델의 모든 입력 변수를 의미한다.
- 데이터의 특성을 추출하기 위해서는 경험이 중요하다.
