## Decision tree
- 다양한 의사결정 경로와 결과를 나타내는데 나무 구조를 사용
- 학습 데이터에 대해 최적의 의사결정나무를 찾는 것은 어려운 문제
- 의사결정나무는 새로운 데이터에 대한 일반화 성능이 좋지 않게 오버피팅되기 쉽다.
- 범주형 결과를 반환하는 분류나무, 숫자형 결과를 반환하는 회귀나무로 나눈다.

### 엔트로피
- 얼마만큼의 정보를 담고 있는가, 데이터의 불확실성을 나타냄(높을수록 불확실도 높음)
- `-plog2p`, p가 0 또는 1에 가까우면 엔트로피는 작을것이다.
- 엔트로피를 구할 때는 레이블과 무관한 확률 값들만 알면 된다.

### 파티션 엔트로피
- 파티션 하나하나가 낮은 엔트로피를 가지는 경우에는 전반적인 엔트로피 낮다.
- 다양한 값을 가질 수 있는 변수를 사용해서 파티션을 나누는 경우 오버피팅이 되어 엔트로피가 낮아진다.

### 의사결정나무 만들기
- 나무는 ID3 알고리즘에 기반해서 구축하는데 이 알고리즘은 탐욕 알고리즘이다. (입문용)
- ID3 알고리즘은 파티션을 나눌때 엔트로피가 가장 낮은 변수를 택하는 것이다. 

### 랜덤포레스트
- 오버피팅을 방지할 수 있는 방법중 하나
- 여러 개의 의사결정나무를 만들고, 그들의 다수결로 결과를 결정하는 방법
- bootstrap의 결과물을 각 나무의 입력값으로 넣어 학습하여, 각 나무가 서로 다른 데이터로 구축되어 랜덤성이 생긴다.(bootstrap aggregating, bagging방법)
- 파티션을 나누는 변수에 랜덤성을 부여한느것, 변수중 일부만 선택하고 그 일부 중에서 최적의 변수를 선택하는 것(ensemble learning), 성능이 떨어지는(bias가 높고 variance가 낮은) 여러 모델을 동시에 활용하여 전체적으로는 성능이 좋은 모델을 구축
